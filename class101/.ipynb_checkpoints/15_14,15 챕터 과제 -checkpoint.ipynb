{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de06522",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cars93-데이터로-SVM과-인공신경망-모델을-이용해-회귀분석-후-R2와-RMSE을-구하고-비교하세요\" data-toc-modified-id=\"Cars93-데이터로-SVM과-인공신경망-모델을-이용해-회귀분석-후-R2와-RMSE을-구하고-비교하세요-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cars93 데이터로 SVM과 인공신경망 모델을 이용해 회귀분석 후 R2와 RMSE을 구하고 비교하세요</a></span><ul class=\"toc-item\"><li><span><a href=\"#전처리\" data-toc-modified-id=\"전처리-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>전처리</a></span><ul class=\"toc-item\"><li><span><a href=\"#결측치를-처리하자\" data-toc-modified-id=\"결측치를-처리하자-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>결측치를 처리하자</a></span></li><li><span><a href=\"#범주형-변수-전처리\" data-toc-modified-id=\"범주형-변수-전처리-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>범주형 변수 전처리</a></span></li><li><span><a href=\"#홀드아웃으로-test-train-나누기\" data-toc-modified-id=\"홀드아웃으로-test-train-나누기-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>홀드아웃으로 test train 나누기</a></span></li><li><span><a href=\"#정규화-스케일-전처리\" data-toc-modified-id=\"정규화-스케일-전처리-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>정규화 스케일 전처리</a></span></li></ul></li><li><span><a href=\"#SVR\" data-toc-modified-id=\"SVR-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>SVR</a></span><ul class=\"toc-item\"><li><span><a href=\"#SVR-그리드-서치\" data-toc-modified-id=\"SVR-그리드-서치-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>SVR 그리드 서치</a></span></li></ul></li><li><span><a href=\"#인공신경망-회귀\" data-toc-modified-id=\"인공신경망-회귀-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>인공신경망 회귀</a></span></li></ul></li><li><span><a href=\"#titanic-데이터로-나이브베이즈-,-SVM,--인공신경망,-KNN-모델을-이용해-분류분석-후-최적의-모델을-선정하고-그-이유를-작성하세요.\" data-toc-modified-id=\"titanic-데이터로-나이브베이즈-,-SVM,--인공신경망,-KNN-모델을-이용해-분류분석-후-최적의-모델을-선정하고-그-이유를-작성하세요.-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>titanic 데이터로 나이브베이즈 , SVM,  인공신경망, KNN 모델을 이용해 분류분석 후 최적의 모델을 선정하고 그 이유를 작성하세요.</a></span><ul class=\"toc-item\"><li><span><a href=\"#전처리\" data-toc-modified-id=\"전처리-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>전처리</a></span><ul class=\"toc-item\"><li><span><a href=\"#결측치-처리\" data-toc-modified-id=\"결측치-처리-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>결측치 처리</a></span></li><li><span><a href=\"#범주형-변수-전처리\" data-toc-modified-id=\"범주형-변수-전처리-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>범주형 변수 전처리</a></span></li><li><span><a href=\"#test-train-split\" data-toc-modified-id=\"test-train-split-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>test train split</a></span></li><li><span><a href=\"#정규화-스케일-전처리\" data-toc-modified-id=\"정규화-스케일-전처리-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>정규화 스케일 전처리</a></span></li></ul></li><li><span><a href=\"#나이브베이즈-분류\" data-toc-modified-id=\"나이브베이즈-분류-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>나이브베이즈 분류</a></span><ul class=\"toc-item\"><li><span><a href=\"#멀티노미얼-분류를-쓰자\" data-toc-modified-id=\"멀티노미얼-분류를-쓰자-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>멀티노미얼 분류를 쓰자</a></span></li></ul></li><li><span><a href=\"#SVC\" data-toc-modified-id=\"SVC-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>SVC</a></span></li><li><span><a href=\"#인공신경망-분류\" data-toc-modified-id=\"인공신경망-분류-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>인공신경망 분류</a></span></li><li><span><a href=\"#KNN\" data-toc-modified-id=\"KNN-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>KNN</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166830b",
   "metadata": {},
   "source": [
    "# Cars93 데이터로 SVM과 인공신경망 모델을 이용해 회귀분석 후 R2와 RMSE을 구하고 비교하세요 \n",
    "* 종속변수 y = Price \n",
    "* 독립변수 X = price제외 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1196e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('./data/Cars93.csv')\n",
    "y = df['Price']\n",
    "X = df.drop(['Min.Price','Price','Max.Price'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f048088",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93 entries, 0 to 92\n",
      "Data columns (total 24 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Manufacturer        93 non-null     object \n",
      " 1   Model               93 non-null     object \n",
      " 2   Type                93 non-null     object \n",
      " 3   MPG.city            93 non-null     int64  \n",
      " 4   MPG.highway         93 non-null     int64  \n",
      " 5   AirBags             93 non-null     object \n",
      " 6   DriveTrain          93 non-null     object \n",
      " 7   Cylinders           93 non-null     object \n",
      " 8   EngineSize          93 non-null     float64\n",
      " 9   Horsepower          93 non-null     int64  \n",
      " 10  RPM                 93 non-null     int64  \n",
      " 11  Rev.per.mile        93 non-null     int64  \n",
      " 12  Man.trans.avail     93 non-null     object \n",
      " 13  Fuel.tank.capacity  93 non-null     float64\n",
      " 14  Passengers          93 non-null     int64  \n",
      " 15  Length              93 non-null     int64  \n",
      " 16  Wheelbase           93 non-null     int64  \n",
      " 17  Width               93 non-null     int64  \n",
      " 18  Turn.circle         93 non-null     int64  \n",
      " 19  Rear.seat.room      91 non-null     float64\n",
      " 20  Luggage.room        93 non-null     int64  \n",
      " 21  Weight              93 non-null     int64  \n",
      " 22  Origin              93 non-null     object \n",
      " 23  Make                93 non-null     object \n",
      "dtypes: float64(3), int64(12), object(9)\n",
      "memory usage: 17.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4b8bc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG.city</th>\n",
       "      <th>MPG.highway</th>\n",
       "      <th>EngineSize</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>RPM</th>\n",
       "      <th>Rev.per.mile</th>\n",
       "      <th>Fuel.tank.capacity</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn.circle</th>\n",
       "      <th>Rear.seat.room</th>\n",
       "      <th>Luggage.room</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.365591</td>\n",
       "      <td>29.086022</td>\n",
       "      <td>2.667742</td>\n",
       "      <td>143.827957</td>\n",
       "      <td>5280.645161</td>\n",
       "      <td>2332.204301</td>\n",
       "      <td>16.664516</td>\n",
       "      <td>5.086022</td>\n",
       "      <td>183.204301</td>\n",
       "      <td>103.946237</td>\n",
       "      <td>69.376344</td>\n",
       "      <td>38.956989</td>\n",
       "      <td>27.829670</td>\n",
       "      <td>-2.540034e+08</td>\n",
       "      <td>3072.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.619812</td>\n",
       "      <td>5.331726</td>\n",
       "      <td>1.037363</td>\n",
       "      <td>52.374410</td>\n",
       "      <td>596.731690</td>\n",
       "      <td>496.506525</td>\n",
       "      <td>3.279370</td>\n",
       "      <td>1.038979</td>\n",
       "      <td>14.602382</td>\n",
       "      <td>6.819674</td>\n",
       "      <td>3.778986</td>\n",
       "      <td>3.223265</td>\n",
       "      <td>2.989072</td>\n",
       "      <td>6.972648e+08</td>\n",
       "      <td>589.896510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3800.000000</td>\n",
       "      <td>1320.000000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-2.147484e+09</td>\n",
       "      <td>1695.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>2620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>3040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>5750.000000</td>\n",
       "      <td>2565.000000</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>3525.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>6500.000000</td>\n",
       "      <td>3755.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>4105.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MPG.city  MPG.highway  EngineSize  Horsepower          RPM  \\\n",
       "count  93.000000    93.000000   93.000000   93.000000    93.000000   \n",
       "mean   22.365591    29.086022    2.667742  143.827957  5280.645161   \n",
       "std     5.619812     5.331726    1.037363   52.374410   596.731690   \n",
       "min    15.000000    20.000000    1.000000   55.000000  3800.000000   \n",
       "25%    18.000000    26.000000    1.800000  103.000000  4800.000000   \n",
       "50%    21.000000    28.000000    2.400000  140.000000  5200.000000   \n",
       "75%    25.000000    31.000000    3.300000  170.000000  5750.000000   \n",
       "max    46.000000    50.000000    5.700000  300.000000  6500.000000   \n",
       "\n",
       "       Rev.per.mile  Fuel.tank.capacity  Passengers      Length   Wheelbase  \\\n",
       "count     93.000000           93.000000   93.000000   93.000000   93.000000   \n",
       "mean    2332.204301           16.664516    5.086022  183.204301  103.946237   \n",
       "std      496.506525            3.279370    1.038979   14.602382    6.819674   \n",
       "min     1320.000000            9.200000    2.000000  141.000000   90.000000   \n",
       "25%     1985.000000           14.500000    4.000000  174.000000   98.000000   \n",
       "50%     2340.000000           16.400000    5.000000  183.000000  103.000000   \n",
       "75%     2565.000000           18.800000    6.000000  192.000000  110.000000   \n",
       "max     3755.000000           27.000000    8.000000  219.000000  119.000000   \n",
       "\n",
       "           Width  Turn.circle  Rear.seat.room  Luggage.room       Weight  \n",
       "count  93.000000    93.000000       91.000000  9.300000e+01    93.000000  \n",
       "mean   69.376344    38.956989       27.829670 -2.540034e+08  3072.903226  \n",
       "std     3.778986     3.223265        2.989072  6.972648e+08   589.896510  \n",
       "min    60.000000    32.000000       19.000000 -2.147484e+09  1695.000000  \n",
       "25%    67.000000    37.000000       26.000000  1.100000e+01  2620.000000  \n",
       "50%    69.000000    39.000000       27.500000  1.400000e+01  3040.000000  \n",
       "75%    72.000000    41.000000       30.000000  1.500000e+01  3525.000000  \n",
       "max    78.000000    45.000000       36.000000  2.200000e+01  4105.000000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673e9eb",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637469f4",
   "metadata": {},
   "source": [
    "### 결측치를 처리하자\n",
    "mean()으로 처리하되, 0.5단위로 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52d85a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Rear.seat.room'].fillna(round(X['Rear.seat.room'].mean()*2)/2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d766c",
   "metadata": {},
   "source": [
    "### 범주형 변수 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e8028e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_cols = ['Manufacturer','Model','Type','AirBags','DriveTrain','Cylinders','Man.trans.avail','Origin','Make']\n",
    "X = pd.get_dummies(columns=dum_cols,data=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08353a3",
   "metadata": {},
   "source": [
    "### 홀드아웃으로 test train 나누기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5eb87377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07bdfcc",
   "metadata": {},
   "source": [
    "### 정규화 스케일 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5599f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test),columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9d02f",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a8798",
   "metadata": {},
   "source": [
    "### SVR 그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ec78bddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>kernel</th>\n",
       "      <th>gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.045560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.045898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.045898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.045898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.045898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.051981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.052019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.052019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.052019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.052019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.053555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.054017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.054017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.054017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.054017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>300</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.060194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.060194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>300</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>300</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>300</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>300</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.061360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.061478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.061478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.061478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.061478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  kernel  gamma  mean_test_score\n",
       "0      10  linear    NaN         0.611311\n",
       "2     100  linear    NaN         0.611311\n",
       "3     300  linear    NaN         0.611311\n",
       "4    1000  linear    NaN         0.611311\n",
       "5   10000  linear    NaN         0.611311\n",
       "1      30  linear    NaN         0.611311\n",
       "16     10     rbf   0.03        -0.045560\n",
       "17     10     rbf   0.10        -0.045898\n",
       "20     10     rbf   3.00        -0.045898\n",
       "19     10     rbf   1.00        -0.045898\n",
       "18     10     rbf   0.30        -0.045898\n",
       "6       1     rbf   0.03        -0.051981\n",
       "7       1     rbf   0.10        -0.052019\n",
       "10      1     rbf   3.00        -0.052019\n",
       "9       1     rbf   1.00        -0.052019\n",
       "8       1     rbf   0.30        -0.052019\n",
       "21     30     rbf   0.03        -0.053555\n",
       "22     30     rbf   0.10        -0.054017\n",
       "25     30     rbf   3.00        -0.054017\n",
       "24     30     rbf   1.00        -0.054017\n",
       "23     30     rbf   0.30        -0.054017\n",
       "31    300     rbf   0.03        -0.060194\n",
       "26    100     rbf   0.03        -0.060194\n",
       "32    300     rbf   0.10        -0.060679\n",
       "27    100     rbf   0.10        -0.060679\n",
       "29    100     rbf   1.00        -0.060679\n",
       "33    300     rbf   0.30        -0.060679\n",
       "34    300     rbf   1.00        -0.060679\n",
       "30    100     rbf   3.00        -0.060679\n",
       "35    300     rbf   3.00        -0.060679\n",
       "28    100     rbf   0.30        -0.060679\n",
       "11      3     rbf   0.03        -0.061360\n",
       "12      3     rbf   0.10        -0.061478\n",
       "15      3     rbf   3.00        -0.061478\n",
       "14      3     rbf   1.00        -0.061478\n",
       "13      3     rbf   0.30        -0.061478"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 테스트하고자 하는 파라미터 값들을 사전타입으로 정의\n",
    "\n",
    "param_grid = [\n",
    "    {'kernel': ['linear'], 'C': [10, 30, 100, 300, 1000,10000]},\n",
    "    {'kernel': ['rbf'], 'C': [1, 3, 10, 30, 100, 300],\n",
    "                        'gamma': [0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "]\n",
    "\n",
    "grid_svr = GridSearchCV(SVR(), param_grid =param_grid, cv = 5)\n",
    "grid_svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "result = pd.DataFrame(grid_svr.cv_results_['params'])\n",
    "result['mean_test_score'] = grid_svr.cv_results_['mean_test_score']\n",
    "result.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "17941210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.05</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>6.35</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.45</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.50</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>6.55</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>6.60</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>6.65</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.70</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.75</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.80</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6.85</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.90</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.95</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7.00</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7.05</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>7.15</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>7.20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>7.25</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>7.30</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.611311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  kernel  mean_test_score\n",
       "99   5.05  linear         0.611311\n",
       "125  6.35  linear         0.611311\n",
       "127  6.45  linear         0.611311\n",
       "128  6.50  linear         0.611311\n",
       "129  6.55  linear         0.611311\n",
       "130  6.60  linear         0.611311\n",
       "131  6.65  linear         0.611311\n",
       "132  6.70  linear         0.611311\n",
       "133  6.75  linear         0.611311\n",
       "134  6.80  linear         0.611311\n",
       "135  6.85  linear         0.611311\n",
       "136  6.90  linear         0.611311\n",
       "137  6.95  linear         0.611311\n",
       "138  7.00  linear         0.611311\n",
       "139  7.05  linear         0.611311\n",
       "140  7.10  linear         0.611311\n",
       "141  7.15  linear         0.611311\n",
       "142  7.20  linear         0.611311\n",
       "143  7.25  linear         0.611311\n",
       "144  7.30  linear         0.611311"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 테스트하고자 하는 파라미터 값들을 사전타입으로 정의\n",
    "\n",
    "param_grid = [\n",
    "    {'kernel': ['linear'], 'C': np.arange(0.1,10,0.05)}\n",
    "]\n",
    "\n",
    "grid_svr = GridSearchCV(SVR(), param_grid =param_grid, cv = 5)\n",
    "grid_svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "result = pd.DataFrame(grid_svr.cv_results_['params'])\n",
    "result['mean_test_score'] = grid_svr.cv_results_['mean_test_score']\n",
    "result.sort_values(by='mean_test_score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bafb6507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.20000000000000004,\n",
       " 'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'epsilon': 0.1,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'linear',\n",
       " 'max_iter': -1,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svr.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2bc8a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data R2 :  0.9999042027220784\n",
      "test data R2 :  0.7081119646866254\n",
      "RMSE :  4.207243116664975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "print(\"train data R2 : \",grid_svr.best_estimator_.score(X_train_scaled,y_train))\n",
    "print(\"test data R2 : \",grid_svr.best_estimator_.score(X_test_scaled,y_test))\n",
    "print(\"RMSE : \", np.sqrt(mean_squared_error(y_test,grid_svr.best_estimator_.predict(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a5e126",
   "metadata": {},
   "source": [
    "## 인공신경망 회귀 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5c07baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data R2 :  0.9999990566608916\n",
      "test data R2 :  0.3266369260721378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(64,64,64,64,64), activation='relu', max_iter = 1000, random_state=2021)\n",
    "mlpr.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"train data R2 : \",mlpr.score(X_train_scaled, y_train))\n",
    "print(\"test data R2 : \",mlpr.score(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f728fdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (64, 64, 64, 64, 64),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 1000,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 2021,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "670f2dd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>alpha</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.373160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.373035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.342809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.333040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.323057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.302477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.301241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.266962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.263341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.253912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.213181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.211217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.196232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.104464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.039324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.029876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.050598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.081649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.122114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.132724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.199852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.202051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.231757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.241970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.260853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.354305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.379635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.486362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.510684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.511796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.561166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.564178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.568676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.641752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.644293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.698635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.718903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.805402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-0.825607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.862090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(16, 16, 16, 16, 16, 16, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-0.946264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64, 64, 64, 64)</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-1.470972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-6.937461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-7.068843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-9.421066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-9.563706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-11.469200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-11.589373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-11.768637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-13.593863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-13.700864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-13.788864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-14.332661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-14.360015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-14.920369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-14.990285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>-15.018356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-15.146228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-16.153062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>-16.512376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation   alpha            hidden_layer_sizes  max_iter solver  \\\n",
       "58       relu  0.0001  (16, 16, 16, 16, 16, 16, 16)      1000    sgd   \n",
       "56       relu  0.0001          (64, 64, 64, 64, 64)      1000    sgd   \n",
       "36       relu  0.0001          (64, 64, 64, 64, 64)      1000    sgd   \n",
       "49       relu  0.0010  (16, 16, 16, 16, 16, 16, 16)      1000  lbfgs   \n",
       "44       relu  0.0010                           100      1000    sgd   \n",
       "37       relu  0.0001          (64, 64, 64, 64, 64)      1000  lbfgs   \n",
       "59       relu  0.0001  (16, 16, 16, 16, 16, 16, 16)      1000  lbfgs   \n",
       "47       relu  0.0010          (64, 64, 64, 64, 64)      1000  lbfgs   \n",
       "57       relu  0.0001          (64, 64, 64, 64, 64)      1000  lbfgs   \n",
       "54       relu  0.0001                           100      1000    sgd   \n",
       "48       relu  0.0010  (16, 16, 16, 16, 16, 16, 16)      1000    sgd   \n",
       "39       relu  0.0001  (16, 16, 16, 16, 16, 16, 16)      1000  lbfgs   \n",
       "34       relu  0.0001                           100      1000    sgd   \n",
       "7        tanh  0.0001          (64, 64, 64, 64, 64)      1000  lbfgs   \n",
       "46       relu  0.0010          (64, 64, 64, 64, 64)      1000    sgd   \n",
       "38       relu  0.0001  (16, 16, 16, 16, 16, 16, 16)      1000    sgd   \n",
       "55       relu  0.0001                           100      1000  lbfgs   \n",
       "45       relu  0.0010                           100      1000  lbfgs   \n",
       "16       tanh  0.0010          (64, 64, 64, 64, 64)      1000    sgd   \n",
       "18       tanh  0.0010  (16, 16, 16, 16, 16, 16, 16)      1000    sgd   \n",
       "35       relu  0.0001                           100      1000  lbfgs   \n",
       "8        tanh  0.0001  (16, 16, 16, 16, 16, 16, 16)      1000    sgd   \n",
       "28       tanh  0.0001  (16, 16, 16, 16, 16, 16, 16)      1000    sgd   \n",
       "32       relu  0.0001                            50      1000    sgd   \n",
       "42       relu  0.0010                            50      1000    sgd   \n",
       "52       relu  0.0001                            50      1000    sgd   \n",
       "43       relu  0.0010                            50      1000  lbfgs   \n",
       "19       tanh  0.0010  (16, 16, 16, 16, 16, 16, 16)      1000  lbfgs   \n",
       "29       tanh  0.0001  (16, 16, 16, 16, 16, 16, 16)      1000  lbfgs   \n",
       "33       relu  0.0001                            50      1000  lbfgs   \n",
       "27       tanh  0.0001          (64, 64, 64, 64, 64)      1000  lbfgs   \n",
       "53       relu  0.0001                            50      1000  lbfgs   \n",
       "31       relu  0.0001                            30      1000  lbfgs   \n",
       "17       tanh  0.0010          (64, 64, 64, 64, 64)      1000  lbfgs   \n",
       "30       relu  0.0001                            30      1000    sgd   \n",
       "51       relu  0.0001                            30      1000  lbfgs   \n",
       "6        tanh  0.0001          (64, 64, 64, 64, 64)      1000    sgd   \n",
       "40       relu  0.0010                            30      1000    sgd   \n",
       "50       relu  0.0001                            30      1000    sgd   \n",
       "41       relu  0.0010                            30      1000  lbfgs   \n",
       "9        tanh  0.0001  (16, 16, 16, 16, 16, 16, 16)      1000  lbfgs   \n",
       "26       tanh  0.0001          (64, 64, 64, 64, 64)      1000    sgd   \n",
       "11       tanh  0.0010                            30      1000  lbfgs   \n",
       "13       tanh  0.0010                            50      1000  lbfgs   \n",
       "21       tanh  0.0001                            30      1000  lbfgs   \n",
       "1        tanh  0.0001                            30      1000  lbfgs   \n",
       "25       tanh  0.0001                           100      1000  lbfgs   \n",
       "23       tanh  0.0001                            50      1000  lbfgs   \n",
       "3        tanh  0.0001                            50      1000  lbfgs   \n",
       "15       tanh  0.0010                           100      1000  lbfgs   \n",
       "4        tanh  0.0001                           100      1000    sgd   \n",
       "14       tanh  0.0010                           100      1000    sgd   \n",
       "24       tanh  0.0001                           100      1000    sgd   \n",
       "12       tanh  0.0010                            50      1000    sgd   \n",
       "2        tanh  0.0001                            50      1000    sgd   \n",
       "22       tanh  0.0001                            50      1000    sgd   \n",
       "5        tanh  0.0001                           100      1000  lbfgs   \n",
       "10       tanh  0.0010                            30      1000    sgd   \n",
       "20       tanh  0.0001                            30      1000    sgd   \n",
       "0        tanh  0.0001                            30      1000    sgd   \n",
       "\n",
       "    mean_test_score  \n",
       "58         0.373160  \n",
       "56         0.373035  \n",
       "36         0.342809  \n",
       "49         0.333040  \n",
       "44         0.323057  \n",
       "37         0.302477  \n",
       "59         0.301241  \n",
       "47         0.266962  \n",
       "57         0.263341  \n",
       "54         0.253912  \n",
       "48         0.213181  \n",
       "39         0.211217  \n",
       "34         0.196232  \n",
       "7          0.104464  \n",
       "46         0.039324  \n",
       "38         0.029876  \n",
       "55        -0.050598  \n",
       "45        -0.081649  \n",
       "16        -0.122114  \n",
       "18        -0.132724  \n",
       "35        -0.199852  \n",
       "8         -0.202051  \n",
       "28        -0.231757  \n",
       "32        -0.241970  \n",
       "42        -0.260853  \n",
       "52        -0.354305  \n",
       "43        -0.379635  \n",
       "19        -0.486362  \n",
       "29        -0.510684  \n",
       "33        -0.511796  \n",
       "27        -0.561166  \n",
       "53        -0.564178  \n",
       "31        -0.568676  \n",
       "17        -0.641752  \n",
       "30        -0.644293  \n",
       "51        -0.698635  \n",
       "6         -0.718903  \n",
       "40        -0.805402  \n",
       "50        -0.825607  \n",
       "41        -0.862090  \n",
       "9         -0.946264  \n",
       "26        -1.470972  \n",
       "11        -6.937461  \n",
       "13        -7.068843  \n",
       "21        -9.421066  \n",
       "1         -9.563706  \n",
       "25       -11.469200  \n",
       "23       -11.589373  \n",
       "3        -11.768637  \n",
       "15       -13.593863  \n",
       "4        -13.700864  \n",
       "14       -13.788864  \n",
       "24       -14.332661  \n",
       "12       -14.360015  \n",
       "2        -14.920369  \n",
       "22       -14.990285  \n",
       "5        -15.018356  \n",
       "10       -15.146228  \n",
       "20       -16.153062  \n",
       "0        -16.512376  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 테스트하고자 하는 파라미터 값들을 사전타입으로 정의\n",
    "\n",
    "parameters = {'hidden_layer_sizes':[30,50,100,(64,64,64,64,64),(16,16,16,16,16,16,16)] ,\n",
    "              'solver': ['sgd', 'lbfgs'], \n",
    "              'activation' : ['tanh','relu'],\n",
    "             'max_iter' : [1000],\n",
    "             'alpha':[0.0001, 0.001, 0.0001]}\n",
    "\n",
    "grid_mlp = GridSearchCV(MLPRegressor(), param_grid = parameters, cv = 5)\n",
    "grid_mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "result = pd.DataFrame(grid_mlp.cv_results_['params'])\n",
    "result['mean_test_score'] = grid_mlp.cv_results_['mean_test_score']\n",
    "result.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "192b638e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (16, 16, 16, 16, 16, 16, 16),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 1000,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'sgd',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_mlp.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c6fba697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR train data R2 :  0.9999042027220784\n",
      "SVR test data R2 :  0.7081119646866254\n",
      "SVR RMSE :  4.207243116664975\n",
      "인공신경망 train data R2 :  0.9999125970107646\n",
      "인공신경망 test data R2 :  0.5710092956569901\n",
      "인공신경망 RMSE :  5.100507643806167\n"
     ]
    }
   ],
   "source": [
    "print(\"SVR train data R2 : \",grid_svr.best_estimator_.score(X_train_scaled,y_train))\n",
    "print(\"SVR test data R2 : \",grid_svr.best_estimator_.score(X_test_scaled,y_test))\n",
    "print(\"SVR RMSE : \", np.sqrt(mean_squared_error(y_test,grid_svr.best_estimator_.predict(X_test_scaled))))\n",
    "\n",
    "print(\"인공신경망 train data R2 : \",grid_mlp.best_estimator_.score(X_train_scaled,y_train))\n",
    "print(\"인공신경망 test data R2 : \",grid_mlp.best_estimator_.score(X_test_scaled,y_test))\n",
    "print(\"인공신경망 RMSE : \", np.sqrt(mean_squared_error(y_test,grid_mlp.best_estimator_.predict(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4eff22",
   "metadata": {},
   "source": [
    "- SVR params: 'C': 0.2, 'kernel': 'linear'\n",
    "- 인공신경망 회귀 params: 'activation': 'relu',  'alpha': 0.0001, 'hidden_layer_sizes': (16, 16, 16, 16, 16, 16, 16)\n",
    "- 인공신경망 회귀 모델의 경우, train R2 에 비해 test 데이터에 대하여 R2 점수가 많이 떨어지는 것으로 보아 train 데이터 세트에 대해 과적합 된 경향이 크다고 할 수 있다.\n",
    "- SVR의 test data R2: __0.71__ 로 인공신경망보다 설명률이 높다.\n",
    "- SVR의 RMSE: __4.21__ 로 인공신경망보다 낮다.\n",
    "- 따라서 도출된 __SVR__ 의 모델이 인공신경망 회귀 모델보다 성능이 좋다고 할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b856f",
   "metadata": {},
   "source": [
    "# titanic 데이터로 나이브베이즈 , SVM,  인공신경망, KNN 모델을 이용해 분류분석 후 최적의 모델을 선정하고 그 이유를 작성하세요. \n",
    "* 종속변수 y = Price \n",
    "* 독립변수 X = price제외 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f345704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_t = pd.read_csv('./data/titanic.csv')\n",
    "y = df_t['survived']\n",
    "X = df_t.drop(['survived'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed1537dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   pclass       891 non-null    int64  \n",
      " 1   sex          891 non-null    object \n",
      " 2   age          714 non-null    float64\n",
      " 3   sibsp        891 non-null    int64  \n",
      " 4   parch        891 non-null    int64  \n",
      " 5   fare         891 non-null    float64\n",
      " 6   embarked     889 non-null    object \n",
      " 7   class        891 non-null    object \n",
      " 8   adult_male   891 non-null    bool   \n",
      " 9   embark_town  889 non-null    object \n",
      "dtypes: bool(1), float64(2), int64(3), object(4)\n",
      "memory usage: 63.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6f5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=['pclass','embarked'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b20b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   sex          891 non-null    object \n",
      " 1   age          714 non-null    float64\n",
      " 2   sibsp        891 non-null    int64  \n",
      " 3   parch        891 non-null    int64  \n",
      " 4   fare         891 non-null    float64\n",
      " 5   class        891 non-null    object \n",
      " 6   adult_male   891 non-null    bool   \n",
      " 7   embark_town  889 non-null    object \n",
      "dtypes: bool(1), float64(2), int64(2), object(3)\n",
      "memory usage: 49.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11998689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0500     43\n",
       "13.0000    42\n",
       "7.8958     38\n",
       "7.7500     34\n",
       "26.0000    31\n",
       "           ..\n",
       "50.4958     1\n",
       "13.8583     1\n",
       "8.4583      1\n",
       "7.7250      1\n",
       "7.5208      1\n",
       "Name: fare, Length: 248, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['fare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2bef593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Third     491\n",
       "First     216\n",
       "Second    184\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e601c",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcf4c6",
   "metadata": {},
   "source": [
    "### 결측치 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2409e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age       sibsp       parch        fare\n",
       "count  714.000000  891.000000  891.000000  891.000000\n",
       "mean    29.699118    0.523008    0.381594   32.204208\n",
       "std     14.526497    1.102743    0.806057   49.693429\n",
       "min      0.420000    0.000000    0.000000    0.000000\n",
       "25%     20.125000    0.000000    0.000000    7.910400\n",
       "50%     28.000000    0.000000    0.000000   14.454200\n",
       "75%     38.000000    1.000000    0.000000   31.000000\n",
       "max     80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d34174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   sex          891 non-null    object \n",
      " 1   age          891 non-null    float64\n",
      " 2   sibsp        891 non-null    int64  \n",
      " 3   parch        891 non-null    int64  \n",
      " 4   fare         891 non-null    float64\n",
      " 5   class        891 non-null    object \n",
      " 6   adult_male   891 non-null    bool   \n",
      " 7   embark_town  891 non-null    object \n",
      "dtypes: bool(1), float64(2), int64(2), object(3)\n",
      "memory usage: 49.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X['age'].fillna(X['age'].mean(), inplace=True)\n",
    "X['embark_town'].fillna(X['embark_town'].describe().top, inplace=True)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9336d1",
   "metadata": {},
   "source": [
    "### 범주형 변수 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd487666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(columns=['sex','class','embark_town'],data=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a226c63",
   "metadata": {},
   "source": [
    "### test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35910db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f706c19",
   "metadata": {},
   "source": [
    "### 정규화 스케일 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f792e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test),columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d4e58d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_First</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.727095</td>\n",
       "      <td>-0.486659</td>\n",
       "      <td>-0.496159</td>\n",
       "      <td>-0.483094</td>\n",
       "      <td>0.821420</td>\n",
       "      <td>-0.736260</td>\n",
       "      <td>0.736260</td>\n",
       "      <td>-0.575497</td>\n",
       "      <td>-0.518497</td>\n",
       "      <td>0.924211</td>\n",
       "      <td>-0.485913</td>\n",
       "      <td>-0.295398</td>\n",
       "      <td>0.610120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.515652</td>\n",
       "      <td>0.382076</td>\n",
       "      <td>-0.496159</td>\n",
       "      <td>0.865151</td>\n",
       "      <td>-1.217404</td>\n",
       "      <td>1.358215</td>\n",
       "      <td>-1.358215</td>\n",
       "      <td>1.737629</td>\n",
       "      <td>-0.518497</td>\n",
       "      <td>-1.082004</td>\n",
       "      <td>2.057983</td>\n",
       "      <td>-0.295398</td>\n",
       "      <td>-1.639021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.108406</td>\n",
       "      <td>-0.486659</td>\n",
       "      <td>-0.496159</td>\n",
       "      <td>-0.446697</td>\n",
       "      <td>0.821420</td>\n",
       "      <td>-0.736260</td>\n",
       "      <td>0.736260</td>\n",
       "      <td>-0.575497</td>\n",
       "      <td>1.928652</td>\n",
       "      <td>-1.082004</td>\n",
       "      <td>-0.485913</td>\n",
       "      <td>-0.295398</td>\n",
       "      <td>0.610120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510283</td>\n",
       "      <td>-0.486659</td>\n",
       "      <td>-0.496159</td>\n",
       "      <td>-0.397178</td>\n",
       "      <td>0.821420</td>\n",
       "      <td>-0.736260</td>\n",
       "      <td>0.736260</td>\n",
       "      <td>-0.575497</td>\n",
       "      <td>1.928652</td>\n",
       "      <td>-1.082004</td>\n",
       "      <td>-0.485913</td>\n",
       "      <td>-0.295398</td>\n",
       "      <td>0.610120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.510283</td>\n",
       "      <td>0.382076</td>\n",
       "      <td>1.957072</td>\n",
       "      <td>-0.105014</td>\n",
       "      <td>0.821420</td>\n",
       "      <td>-0.736260</td>\n",
       "      <td>0.736260</td>\n",
       "      <td>-0.575497</td>\n",
       "      <td>1.928652</td>\n",
       "      <td>-1.082004</td>\n",
       "      <td>-0.485913</td>\n",
       "      <td>-0.295398</td>\n",
       "      <td>0.610120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0.974300</td>\n",
       "      <td>0.382076</td>\n",
       "      <td>-0.496159</td>\n",
       "      <td>0.386300</td>\n",
       "      <td>0.821420</td>\n",
       "      <td>-0.736260</td>\n",
       "      <td>0.736260</td>\n",
       "      <td>1.737629</td>\n",
       "      <td>-0.518497</td>\n",
       "      <td>-1.082004</td>\n",
       "      <td>-0.485913</td>\n",
       "      <td>-0.295398</td>\n",
       "      <td>0.610120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0.022997</td>\n",
       "      <td>0.382076</td>\n",
       "      <td>0.730457</td>\n",
       "      <td>-0.211812</td>\n",
       "      <td>-1.217404</td>\n",
       "      <td>1.358215</td>\n",
       "      <td>-1.358215</td>\n",
       "      <td>-0.575497</td>\n",
       "      <td>-0.518497</td>\n",
       "      <td>0.924211</td>\n",
       "      <td>2.057983</td>\n",
       "      <td>-0.295398</td>\n",
       "      <td>-1.639021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>-0.069738</td>\n",
       "      <td>-0.486659</td>\n",
       "      <td>-0.496159</td>\n",
       "      <td>-0.511484</td>\n",
       "      <td>0.821420</td>\n",
       "      <td>-0.736260</td>\n",
       "      <td>0.736260</td>\n",
       "      <td>-0.575497</td>\n",
       "      <td>-0.518497</td>\n",
       "      <td>0.924211</td>\n",
       "      <td>2.057983</td>\n",
       "      <td>-0.295398</td>\n",
       "      <td>-1.639021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>-0.417751</td>\n",
       "      <td>2.119546</td>\n",
       "      <td>1.957072</td>\n",
       "      <td>4.554748</td>\n",
       "      <td>-1.217404</td>\n",
       "      <td>1.358215</td>\n",
       "      <td>-1.358215</td>\n",
       "      <td>1.737629</td>\n",
       "      <td>-0.518497</td>\n",
       "      <td>-1.082004</td>\n",
       "      <td>-0.485913</td>\n",
       "      <td>-0.295398</td>\n",
       "      <td>0.610120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>3.178379</td>\n",
       "      <td>-0.486659</td>\n",
       "      <td>-0.496159</td>\n",
       "      <td>-0.501169</td>\n",
       "      <td>0.821420</td>\n",
       "      <td>-0.736260</td>\n",
       "      <td>0.736260</td>\n",
       "      <td>-0.575497</td>\n",
       "      <td>-0.518497</td>\n",
       "      <td>0.924211</td>\n",
       "      <td>-0.485913</td>\n",
       "      <td>3.385262</td>\n",
       "      <td>-1.639021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>623 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age     sibsp     parch      fare  adult_male  sex_female  sex_male  \\\n",
       "0   -0.727095 -0.486659 -0.496159 -0.483094    0.821420   -0.736260  0.736260   \n",
       "1    1.515652  0.382076 -0.496159  0.865151   -1.217404    1.358215 -1.358215   \n",
       "2   -0.108406 -0.486659 -0.496159 -0.446697    0.821420   -0.736260  0.736260   \n",
       "3    0.510283 -0.486659 -0.496159 -0.397178    0.821420   -0.736260  0.736260   \n",
       "4    0.510283  0.382076  1.957072 -0.105014    0.821420   -0.736260  0.736260   \n",
       "..        ...       ...       ...       ...         ...         ...       ...   \n",
       "618  0.974300  0.382076 -0.496159  0.386300    0.821420   -0.736260  0.736260   \n",
       "619  0.022997  0.382076  0.730457 -0.211812   -1.217404    1.358215 -1.358215   \n",
       "620 -0.069738 -0.486659 -0.496159 -0.511484    0.821420   -0.736260  0.736260   \n",
       "621 -0.417751  2.119546  1.957072  4.554748   -1.217404    1.358215 -1.358215   \n",
       "622  3.178379 -0.486659 -0.496159 -0.501169    0.821420   -0.736260  0.736260   \n",
       "\n",
       "     class_First  class_Second  class_Third  embark_town_Cherbourg  \\\n",
       "0      -0.575497     -0.518497     0.924211              -0.485913   \n",
       "1       1.737629     -0.518497    -1.082004               2.057983   \n",
       "2      -0.575497      1.928652    -1.082004              -0.485913   \n",
       "3      -0.575497      1.928652    -1.082004              -0.485913   \n",
       "4      -0.575497      1.928652    -1.082004              -0.485913   \n",
       "..           ...           ...          ...                    ...   \n",
       "618     1.737629     -0.518497    -1.082004              -0.485913   \n",
       "619    -0.575497     -0.518497     0.924211               2.057983   \n",
       "620    -0.575497     -0.518497     0.924211               2.057983   \n",
       "621     1.737629     -0.518497    -1.082004              -0.485913   \n",
       "622    -0.575497     -0.518497     0.924211              -0.485913   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  \n",
       "0                 -0.295398                 0.610120  \n",
       "1                 -0.295398                -1.639021  \n",
       "2                 -0.295398                 0.610120  \n",
       "3                 -0.295398                 0.610120  \n",
       "4                 -0.295398                 0.610120  \n",
       "..                      ...                      ...  \n",
       "618               -0.295398                 0.610120  \n",
       "619               -0.295398                -1.639021  \n",
       "620               -0.295398                -1.639021  \n",
       "621               -0.295398                 0.610120  \n",
       "622                3.385262                -1.639021  \n",
       "\n",
       "[623 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018681c3",
   "metadata": {},
   "source": [
    "## 나이브베이즈 분류 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ececec9",
   "metadata": {},
   "source": [
    "### 멀티노미얼 분류를 쓰자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "375af72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_clf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87749c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.6902985074626866\n",
      "정밀도 : 0.6428571428571429\n",
      "재현율 : 0.4368932038834951\n",
      "F1 스코어 : 0.5202312138728323\n",
      "ROC_AUC_SCORE : 0.6426890261841718\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred[0]</th>\n",
       "      <th>Pred[1]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True[0]</th>\n",
       "      <td>140</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True[1]</th>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pred[0]  Pred[1]\n",
       "True[0]      140       25\n",
       "True[1]       58       45"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(f\"정확도 : {accuracy_score(y_test, y_pred_clf)}\")\n",
    "print(f\"정밀도 : {precision_score(y_test, y_pred_clf)}\")\n",
    "print(f\"재현율 : {recall_score(y_test, y_pred_clf)}\")\n",
    "print(f\"F1 스코어 : {f1_score(y_test, y_pred_clf)}\")\n",
    "print(f\"ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_clf)}\")\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred_clf),\n",
    "             index=['True[0]', 'True[1]'],\n",
    "             columns=['Pred[0]','Pred[1]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02d0e9",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f30ed71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc = svc.fit(X_train_scaled, y_train)\n",
    "#y_pred_svc = svc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675589dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {'kernel': ['linear'], 'C': [10, 30, 100, 300, 1000,10000]},\n",
    "    {'kernel': ['rbf'], 'C': [1, 3, 10, 30, 100, 300],\n",
    "                        'gamma': [0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "]\n",
    "#parameters = {'gamma':[0.1, 1, 10] ,'C': [0.01, 0.1 ,0.5, 1, 10,20,30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc1025a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.776053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.774205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.763871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.762757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.762585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.759871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>30.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.759647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.759623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.759055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.757667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.755774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.754507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.752791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.751293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.751036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.748295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>30.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.748295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.748159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.743632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.740548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.738294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.738157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>30.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.734627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.731561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.727801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.727036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>30.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.722536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.721408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.718043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.716422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.707101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.698463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.695797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.695797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.691879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.689278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.432798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.181907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  gamma  mean_test_score\n",
       "25   5.00   0.01         0.776053\n",
       "20   3.00   0.01         0.774205\n",
       "21   3.00   0.05         0.763871\n",
       "17   1.00   0.10         0.762757\n",
       "35  20.00   0.01         0.762585\n",
       "16   1.00   0.05         0.759871\n",
       "40  30.00   0.01         0.759647\n",
       "30  10.00   0.01         0.759623\n",
       "11   0.50   0.05         0.759055\n",
       "22   3.00   0.10         0.757667\n",
       "27   5.00   0.10         0.755774\n",
       "12   0.50   0.10         0.754507\n",
       "31  10.00   0.05         0.752791\n",
       "32  10.00   0.10         0.751293\n",
       "26   5.00   0.05         0.751036\n",
       "36  20.00   0.05         0.748295\n",
       "41  30.00   0.05         0.748295\n",
       "15   1.00   0.01         0.748159\n",
       "37  20.00   0.10         0.743632\n",
       "6    0.10   0.05         0.740548\n",
       "7    0.10   0.10         0.738294\n",
       "18   1.00   1.00         0.738157\n",
       "42  30.00   0.10         0.734627\n",
       "33  10.00   1.00         0.733333\n",
       "13   0.50   1.00         0.731561\n",
       "28   5.00   1.00         0.727801\n",
       "23   3.00   1.00         0.727036\n",
       "43  30.00   1.00         0.722536\n",
       "5    0.10   0.01         0.721408\n",
       "10   0.50   0.01         0.718043\n",
       "38  20.00   1.00         0.716422\n",
       "19   1.00  10.00         0.707101\n",
       "24   3.00  10.00         0.698463\n",
       "29   5.00  10.00         0.695797\n",
       "34  10.00  10.00         0.695797\n",
       "39  20.00  10.00         0.691879\n",
       "44  30.00  10.00         0.689278\n",
       "14   0.50  10.00         0.432798\n",
       "8    0.10   1.00         0.181907\n",
       "1    0.01   0.05         0.000000\n",
       "9    0.10  10.00         0.000000\n",
       "4    0.01  10.00         0.000000\n",
       "3    0.01   1.00         0.000000\n",
       "2    0.01   0.10         0.000000\n",
       "0    0.01   0.01         0.000000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 테스트하고자 하는 파라미터 값들을 사전타입으로 정의\n",
    "\n",
    "parameters = {'gamma':[0.01, 0.05, 0.1, 1, 10] ,'C': [0.01, 0.1 ,0.5, 1, 3, 5, 10,20,30]}\n",
    "\n",
    "grid_svc = GridSearchCV(SVC(), param_grid = parameters, cv = 5, scoring='f1')\n",
    "grid_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "result = pd.DataFrame(grid_svc.cv_results_['params'])\n",
    "result['mean_test_score'] = grid_svc.cv_results_['mean_test_score']\n",
    "result.sort_values(by='mean_test_score', ascending=False)\n",
    "\n",
    "#y_pred_svc = grid_svc.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d43c210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 0.01,\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svc.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4aeb90eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_svc = grid_svc.best_estimator_.predict(X_test_scaled)\n",
    "y_pred_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40436635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.8097014925373134\n",
      "정밀도 : 0.776595744680851\n",
      "재현율 : 0.7087378640776699\n",
      "F1 스코어 : 0.7411167512690355\n",
      "ROC_AUC_SCORE : 0.7907325684024714\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred[0]</th>\n",
       "      <th>Pred[1]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True[0]</th>\n",
       "      <td>144</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True[1]</th>\n",
       "      <td>30</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pred[0]  Pred[1]\n",
       "True[0]      144       21\n",
       "True[1]       30       73"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(f\"정확도 : {accuracy_score(y_test, y_pred_svc)}\")\n",
    "print(f\"정밀도 : {precision_score(y_test, y_pred_svc)}\")\n",
    "print(f\"재현율 : {recall_score(y_test, y_pred_svc)}\")\n",
    "print(f\"F1 스코어 : {f1_score(y_test, y_pred_svc)}\")\n",
    "print(f\"ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_svc)}\")\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred_svc),\n",
    "             index=['True[0]', 'True[1]'],\n",
    "             columns=['Pred[0]','Pred[1]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f2e812",
   "metadata": {},
   "source": [
    "## 인공신경망 분류 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0129bcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/Users/hmc/opt/anaconda3/envs/ADP_Class/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.882997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.882774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.872960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.872198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.871211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.870691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.868983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.866999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.866237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanh</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.865196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.862802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.862740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.859273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.857482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.854821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.853425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation  hidden_layer_sizes  max_iter solver  mean_test_score\n",
       "12       relu                  50      1000    sgd         0.882997\n",
       "14       relu                 100      1000    sgd         0.882774\n",
       "4        tanh                  50      1000    sgd         0.872960\n",
       "10       relu                  30      1000    sgd         0.872198\n",
       "9        relu                  10      1000   adam         0.871211\n",
       "6        tanh                 100      1000    sgd         0.870691\n",
       "0        tanh                  10      1000    sgd         0.868983\n",
       "1        tanh                  10      1000   adam         0.866999\n",
       "11       relu                  30      1000   adam         0.866237\n",
       "2        tanh                  30      1000    sgd         0.865196\n",
       "8        relu                  10      1000    sgd         0.862802\n",
       "13       relu                  50      1000   adam         0.862740\n",
       "5        tanh                  50      1000   adam         0.859273\n",
       "3        tanh                  30      1000   adam         0.857482\n",
       "15       relu                 100      1000   adam         0.854821\n",
       "7        tanh                 100      1000   adam         0.853425"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 테스트하고자 하는 파라미터 값들을 사전타입으로 정의\n",
    "\n",
    "parameters = {'hidden_layer_sizes':[10,30,50,100] ,\n",
    "              'solver': ['sgd', 'adam'], \n",
    "              'activation' : ['tanh','relu'],\n",
    "             'max_iter' : [1000]}\n",
    "\n",
    "grid_mlpc = GridSearchCV(MLPClassifier(), param_grid = parameters, cv = 5, scoring='f1')\n",
    "grid_mlpc.fit(X_train_scaled, y_train)\n",
    "\n",
    "result = pd.DataFrame(grid_mlpc.cv_results_['params'])\n",
    "result['mean_test_score'] = grid_mlpc.cv_results_['mean_test_score']\n",
    "result.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a724bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpc = grid_mlpc.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cf3b73c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7985074626865671\n",
      "정밀도 : 0.7634408602150538\n",
      "재현율 : 0.6893203883495146\n",
      "F1 스코어 : 0.7244897959183674\n",
      "ROC_AUC_SCORE : 0.7779935275080907\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred[0]</th>\n",
       "      <th>Pred[1]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True[0]</th>\n",
       "      <td>143</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True[1]</th>\n",
       "      <td>32</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pred[0]  Pred[1]\n",
       "True[0]      143       22\n",
       "True[1]       32       71"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(f\"정확도 : {accuracy_score(y_test, y_pred_mlpc)}\")\n",
    "print(f\"정밀도 : {precision_score(y_test, y_pred_mlpc)}\")\n",
    "print(f\"재현율 : {recall_score(y_test, y_pred_mlpc)}\")\n",
    "print(f\"F1 스코어 : {f1_score(y_test, y_pred_mlpc)}\")\n",
    "print(f\"ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_mlpc)}\")\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred_mlpc),\n",
    "             index=['True[0]', 'True[1]'],\n",
    "             columns=['Pred[0]','Pred[1]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9b59b",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae87108b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEiCAYAAAABGF7XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABMbUlEQVR4nO3dd3Rc5bXw4d9Ws6plq9jYcpG7TXHH2BRjU00PEAKEFkJoMaEkIZDk3psAN1+4SUgDQgkldEKPAwktuACm2HIvuDdJxpYtS1aXZmZ/f5wz8lhWOZJGnpG0n7W0Zua02XKZPect+xVVxRhjjGmNmEgHYIwxpvOx5GGMMabVLHkYY4xpNUsexhhjWs2ShzHGmFaz5GGMMabVLHkYY4xpNU/JQ0RSRCQm5HWMiCR3XFjGGGOimdc7j/8AockiGfgw/OEYY4zpDLwmj0RVLQ++cJ/bnYcxxnRTXpNHhYhMDL4QkUlAVceEZIwxJtrFeTzuduBVESl0X/cDLu2QiIwxxkQ98VoYUUTigVGAAF+pal1HBmaMMSZ6eUoeInJ1Y9tV9dmwR2SMMSbqeW22OjbkeSJwKrAEsORhjDHdkOdmq4NOEkkHnlPV88MfkjHGmGjX1hnmlcCIcAZijDGm8/DUbCUi/wSCtygxwJHAKx0VlDHGmOjmtcP85JCXPmCbquZ3WFTGGGOiWpv6PIwxxnRvXgsjThWRRSJSLiK1IuIXkf0dHZwxxpjo5LXD/CHgcmADkAR8D3iwo4IyxhgT3bzO80BVN4pIrKr6gadFZGEHxmWMMSaKeU0elSKSACwTkd8AO4GUjgvLGGNMNPPabHWVe+wtQAUwELi4o4IyxhgT3cIy2kpEXldVSybGGNNNhGsN86Fhuo4xxphOIFzJwyaLGGNMNxKu5GGMMaYbCVfykDBdxxhjTCfgdYZ5iojEhLyOEZHkkEPuCntkxhhjopbXO4//AKHJIhn4MPhCVd8PZ1DGGGOim9fkkaiq5cEX7vPkZo43xhjThXmdYV4hIhNVdQmAiEwCqjourPDLysrS3NzcSIdhjDGdSl5e3h5VzW643WvyuB14VUQK3df9gEvDFNthkZuby+LFiyMdhjHGdCoisq2x7Z6Sh6ouEpHRwCickVVfqWpdGOMzxnQwf0CpqvNTWeujujZQ/7yqzk91nZ/KWj9VtQeex8YIY/r15Oj+6aQnx0c6fBNlvC5DGw/cDEx3N80TkccsgRgTHoGAUu1zPrwr3Q/wquAHep2f6tqQ5yHbq9wP/Kq6kNdNPNb6A22Ob3BmMsfkpDs/A9I5OiednomWULozr81WjwDxwF/c11e5277XEUEZ0xVV1PjYVFTOxt0hP0XlFJZUUV3X+g/2hNgYEuNjSEqIJSk+lqSEOJLc172TE9ztMSQnxJEY7xyTnBBLYsKB50nxsc6+hINfJyfEUuMLsLqwlBX5pawqKGXp9hLeXrGz/v1zM5M5ZkAvjsnpyTE5vTgqp6cllG7E6xrmy1V1XEvbotnkyZPV+jzM4bC3vKY+MQSTxKbd5RSWVtcfExcjDM5MZnifVAZlJJOcEOd8eCcc+PBOig8mhdiQBHHgAz4+9vAXiCiuqGVlgZNMVuSXsKpgPwUlB8bODMlKOegO5aj+PUmzhNKpiUieqk5uuN3rnYdfRIap6ib3YkMBfzgDNKYzCQSUgpIqNhY5iaE+SRSVs6/yQGtuckIsw7JTmTIkg+F9Uut/BmemROTDv70yUhI4eWQ2J488MPhmb3lNSEIpZfHWYuYsL6zfPzQ7JKHkpHNUTjqpPTyvQ2eilNc7j1OAvwGbcTrMBwPXqurcDo0ujOzOw7RFrS/Atr0VBzUzbdxdzuaiCqrqDnx/ykhJYHh2KsNCEsTwPqn065lITEz3q96zJ5hQ8ktZ4SaWne6dlwgMde9Qjs5JZ+yAXhzVvycpUZhQan0BSipr2VtRy74K97Gylr3l7qO7vbiilspaP3179iCnVxL9eyWR09t5HOC+jsbfz4um7jxaTB4iEgvcitPfETraqqYjAu0oljxMc5rqj9i2txJ/4MD/kZxeSU6CyD44SWSkJEQw+s6hqKym/u4keKfy9f4DCWVYdupBTV5H9gtvQlFVymp8FJfXUlxZe+AxNDGEJIjiilrKqn1NXi89KZ6MlAQyUhLonZxAckIsX++vprCkiq9Lq/EFDv5s7ZUcT/90J6nk9EpqkGQSyUrpEZVfNNqcPNyT56rqzA6J7DCx5GFUlb0VtQc1MTXVH5GblXJIghiSldJpvz1Gq91l1fUJZVWBk1R27Xe+l4rA8GBCGeAklSP79yQ5wfk7aM1dQbG7r87f+OddQmxMfSJo+NM7JYFMN0FkpjqPvZLjm2129AeU3WXVFOyroqDE+SksqaJgXxWFJdUUlFRRXnNwYkqIi6F/eqKTUEISSzDR9OuVSI+42DD9yXvX3uTxKyAd+DvOMrQABGecdwaWPLqnHcWVzFu3m/nri8jbtq/R/ohgcgg+H5yZ3Cn7I7qK3furWRmSUFYUlFJU5iSUGIF+6Unsr65r8a4g0/3gz0hJICM5gYxU97GR5JCSEIvI4f3WX1pVdyChlFYdkmh2l9XQ8OM5O61HSFNY4iFJJj0pPuy/R7vvPBrZrKp6SjiCOxwseXQP1XV+Pt+8l3nriliwvojNe5zvOoMykjl+WCYj+qZ1+/6IzmjX/mpWuv0nO4orD2oyOigRJCfQOzmeuC6Q/Gt9Ab4urT70ziUk0dT4Dh7inZIQS/9G7lpOHplN7zY2rbYreXQFljy6JlVl854K5q8rYv76Ij7fvJcaX4AecTFMG5bJjJHZnDyqD7mZyYf9m6UxHSnYDBtMKk6CqaagpLK+aay4ohaAf992EmP69WzT+7R3qK4xUaOixsfCTXuZv95pjtpR7MwzGJadwhXHDWbGqGymDMkgMf7wtw8bc7iICFmpPchK7cHYAb0aPaaq1k9BSRWDMsJfBN2Sh4l6qsr6XeX1fReLthZT51eSE2I5flgWN04fxskjsxnYAf9BjOnMkhJiGd4ntUOubcnDRKXSqjoWbtzDPLc5Kjikc/QRaXz3hCGcPCqbyYMzSIjr/G3bxnRGzSYPEbmouf2q+kZ4wzHdVSCgrNm5n/nri5i3bjdLtpfgDyhpiXGcNCLLndXchyPSEyMdqjGGlu88znMf+wDHAx+5r2cC84AWk4eIzAL+BMQCT6jq/Q32pwPPA4PceH6nqk83d66IZOAMG84FtgLfUtV9LcViosu+iloWbHDuLBas38Oecmc45tE5Pbn55GGcPCqbCQN7dYmRM8Z0Nc0mD1W9FkBE3gaOVNWd7ut+wMMtXdydnf4wcDqQDywSkTmquibksNnAGlU9T0SygXUi8gJO7aymzr0b+I+q3i8id7uv72rNL24OP39AWZFfUt8UtTy/BFXonRzPSSOymTEqm5NGZJOd1iPSoRpjWuC1zyM3mDhcu4CRHs6bAmxU1c0AIvIycAEQmjwUSBNnHGUqUAz4gOOaOfcCYIZ7/jM4d0GWPKJQUVkNC9YXMW99ER9vKKKksg4RGD+wF7edOoKTR2YzdkAvYm2+hTGditfkMU9E3gNewvmwvwzwUhQxB9gR8jofJymEegiYAxQCacClqhoQkebO7RtMZqq6U0T6ePw9TAfz+QMs2V7C/PW7mbeuiNWF+wHISu3BqaP7cvKobE4antXmCUvGmOjgdRnaW0TkQg6sJPi4qr7p4dTGvk42nJV4JrAMOAUYBnwgIh97PLf5Nxe5AbgBYNCgQa051bRSrS/AG0vy+cu8TWwvriQ2Rpg0qDd3njmKk0dmc2S/njab25gupDVDdZcAZar6oYgki0iaqpa1cE4+MDDk9QCcO4xQ1wL3qzPVfaOIbAFGt3DuLhHp59519AN2N/bmqvo48Dg4M8xb/hVNa1XX+fn7oh08Nn8ThaXVjB2Qzo/PnMCMUdm2qpwxXZjXNcyvx/kGn4Fzd5ADPAqc2sKpi4ARIjIEKMBp7vp2g2O2u9f5WET64pR93wyUNHPuHOAa4H738R9efg8TPuU1Pl74fBt//XgLe8prODa3N7++eCzTR2RZGRBjugGvdx6zcTq/vwBQ1Q1e+hlU1ScitwDv4Qy3fUpVV4vITe7+R4H7gL+JyEqcpqq7VHUPQGPnupe+H3hFRK7DST6XePw9TDuVVtXxzMKtPPXpFkoq6zhpRBa3zJzAcUMzIx2aMeYw8po8alS1NviNUkTi8Nj/oKr/Av7VYNujIc8LgTO8nutu30vLdz0mjPaW1/DkJ1t47rNtlNX4OG1MH2bPHM6EQb0jHZoxJgK8Jo/5IvIzIElETge+D/yz48Iy0WLX/moeX7CZF7/YTrXPz9nH9GP2jOEc2b9tFTqNMV2D1+RxN3AdsBK4EfiXqv61w6IyEbejuJLHFmzilUX5+FW5YHx/vj9jeIcVWTPGdC5ek8cPVPVPQH3CEJHb3G2mC9lcVM5f5m3iraUFiMAlkwdy0/RhDMq0irXGmAO8Jo9rcGpMhfpOI9tMJ/XV1/t5eO4m3llRSEJcDFdNG8wN04fSLz0p0qEZY6JQS1V1L8cZHjtEROaE7EoD9nZkYObwWJFfwkMfbeT9NbtISYjlhunDuO7EIVZfyhjTrJbuPBYCO4Es4IGQ7WXAio4KynS8RVuLefCjjSxYX0TPxDhuP20E3zk+l17JVjbEGNOylqrqbgO2AdMOTzimI6kqn27cy4MfbeCLLcVkpiRw16zRXDl1EGk2G9wY0wpeZ5hPBR4ExgAJOJP2KlTVxmt2AqrKf9bu5qG5G1m2o4Qjeibyi/OO5LJjB5GUYOt8G2Naz2uH+UM45UFeBSYDVwPDOyooEx7+gPLuqq95aO5G1u7cz4DeSfy/C4/h4kk59IizpGGMaTvPhRFVdaOIxKqqH3haRBZ2YFymHXz+AHOWF/Lw3I1sKqpgaHYKD1wyjvPH9yfeVuUzxoSB1+RRKSIJwDIR+Q1OJ3pKx4Vl2qLG5+f1vAIemb+RHcVVjD4ijYe/PZFZRx9hiy0ZY8LKa/K4Cqef4xbgDpxS6Rd3VFCmdapq/by8aDuPzd/M1/urGTewF7849yhOHdPHKtwaYzqE18WgtrlPq4B7Oi4c0xrlNT6e+2wbT3y8mb0VtRw3JIPfXTKOE4ZnWtIwxnSoliYJrqSZ6rmqOjbsEZkWVdf5efKTLTy+YDOlVXVMH5nNLTOHM2VIRqRDM8Z0Ey3deZzrPs52H59zH68AKjskItOkQED554pCfvPuOgpKqjh1dB9uPXUE4wb2inRoxphuxsskQUTkBFU9IWTX3SLyKXBvS28gIrNwamDFAk+o6v0N9t+Jk4yC8YwBst2fv4ccOhT4H1X9o4j8ErgeKHL3/cxd+6PLWry1mPveWcvyHSUcndOTB741jqm2AJMxJkK8dpiniMiJqvoJgIgcj4fRViISCzwMnI6zJvkiEZmjqmuCx6jqb4HfusefB9yhqsVAMTA+5DoFwJshl/+Dqv7OY/yd1va9ldz/7lr+tfJrjuiZyAOXjOPCCTnE2OgpY0wEeU0e1wFPiUi6+7oE+K6H86YAG1V1M4CIvAxcAKxp4vjLgZca2X4qsCmk477LK62q4+G5G/nbp1uJjRHuOG0k108fQnKC56k5xhjTYbyOtsoDxolIT0BUtdTj9XOAHSGv84HjGjtQRJKBWTjDgRu6jEOTyi0icjWwGPiRqu7zGFNUq/MHeOnL7fzhg/WUVNVxyaQB/OiMUfTtmRjp0Iwxpl5Lo62uVNXnReSHDbYDoKq/b+H6jbWtNDV66zzgU7fJKvS9EoDzgZ+GbH4EuM+91n04FX8PuRMSkRuAGwAGDRrUQqiRpap89NVufvWvtWwuquD4YZn8/JwxHNU/veWTjTHmMGvpziPYr5HWxuvn40woDBoAFDZxbGN3FwBnAUtUdVdwQ+hzEfkr8HZjF1TVx4HHASZPntzkkONIW1O4n1/9aw2fbtzL0OwUnrh6sk3wM8ZEtZZGWz3mPrZ1YuAiYISIDMHp8L4MZ3Gpg7h9KScDVzZyjUP6QUSkn6rudF9eCKxqY3wRtXt/Nb97fx2v5uXTKymee84/im8fN8jqTxljol5LzVZ/bm6/qt7awn6fiNwCvIczVPcpVV0tIje5+x91D70QeF9VKxq8fzLOSK0bG1z6NyIyHqfZamsj+6NaVa2fv368mUfnb6LOH+D6k4Yye+Zw0pNsTQ1jTOcgqk235ojINc2drKrPhD2iDjJ58mRdvHhxRGMIBJS3lhXwm3fX8fX+as4+5gjumjWawZlWY9IYE51EJE9VJzfc3lKzVadJDtHu8817+dU7a1lZUMq4Aek8+O0JHJtr5USMMZ2T15UEs4G7gCOB0DGj5wFVqhpwj4sBElXVSpe4tuyp4P5/r+W91bvon57IHy8dz/nj+tskP2NMp+Z1xtkLOKVCzgFuAq7BKQ3yH+A0oNw9Lhl4Hzg+vGF2PiWVtfz5Pxt57vOtJMTGcOeZo7juxCEkxtsKfsaYzs9r8shU1SdF5DZVnQ/MF5H5OHcZwcSBqpa7ndzdVq0vwPOfb+NP/9lAWXUdlx47iDtOH0GfNJvkZ4zpOrwmjzr3caeInIMzV2MA8LWITFTVJQAiMglnzY9uR1X5YM0ufv3vr9iyp4KTRmTx83PGMPqInpEOzRhjws5r8vhfdy7Gj4AHgZ44KwruBF4VkeDEv37ApWGPMsqtKijlvrfX8MWWYob3SeXpa49lxshsm+RnjOmyvCaPL9x6VqXAzNAdIjIaGIVTiuQrVa1r5Pwu6evSan773jreWJpPRnIC933jaC4/diBxNsnPGNPFeU0eC0VkC06n+RvBIoRuYcJQE0QEVX02nEFGm4oaH48t2MzjCzYRCMCN04fx/ZnD6Jlok/yMMd2D16q6I0RkCk55kZ+LyBrgZeDYkMMScUqnLwG6ZPLwB5TXl+Tzu/fWsbushnPH9uOuWaMZmNGtxwgYY7ohz4tDqOqXwJci8v+A3wPPqOpB407dfpHnGju/s1u4cQ//+85a1uzcz4RBvXjkyklMGtw70mEZY0xEeJ0k2BOn/tRlwDCcFf2mNHJoJTAibNFFgU1F5fz6X1/x4dpdDOidxIOXT+Dcsf2sM9wY0615vfNYDrwF3KuqnwU3isg/ObA+RwzODPRXwhlgpN3zzzUs2baPu88azXeOz7VJfsYYg/fkMVTdCooicq6qBtfPCF1D3AdsU9X8cAYYab/6xtEkJcSSldoj0qEYY0zU8NphHlp6917cxZfc2eZdmnWGG2PMoZotyd7oCSJLVXWC+3wqzqTBMUACzpodFaoaddOqRaQI2NbG07OAPWEMJ1wsrtaxuFrH4mqdrhrXYFXNbrjR82irEKELLz2E04n+KjAZuBoY3qbwOlhjv7xXIrK4sXr2kWZxtY7F1ToWV+t0t7g8TYUWkUtEJLiO+Zki8oaITARQ1Y1ArKr6VfVpGsxAN8YY0/V4raPx36paJiIn4iwL+wzwCFApIgnAMhH5jYjcAdiyeMYY08V5TR5+9/Ec4FFV/QdOH8dV7jVuASqAgcDF4Q4yCjwe6QCaYHG1jsXVOhZX63SruDx1mIvI20ABzsJPwbLrX6rquBbOe11Vu2IyMcaYbs3rnce3gPeAWapaAmQAd3o4b2gb4zLGGBPFvI626ge8o6o1IjIDGIu34oetGwdsjDGmU/B65/E64BeR4cCTwBDgxQ6LKkqIyFMisltEVkU6llAiMlBE5orIWhFZLSK3RTomABFJFJEvRWS5G9c9kY4pSERiRWSp2wQbNURkq4isFJFlIrI40vEEiUgvEXlNRL5y/51Ni4KYRrl/TsGf/SJye6TjAhCRO9x/86tE5CURiYp1p0XkNjem1eH+s/KaPAKq6gMuAv6oqnfg3I20pLNXD/wbMCvSQTTCB/xIVccAU4HZInJkhGMCqAFOcfvCxgOz3Imk0eA2YG2kg2jCTFUdH2VzBP4EvKuqo4FxRMGfnaquc/+cxuP0vVbiFGmNKBHJAW4FJqvq0TiTpS+LbFQgIkcD1+MUsR0HnCsiYStc6zV51InI5TiTAIPf3OJFJEVE6q8hIjEiElrP464wxRkRqroAKI50HA2p6s7guvGqWobzHzsnslE5ZWxUtdx9Ge/+RLzpUkQG4IwUfCLSsXQGbhXt6TitDKhqrdvXGU1OBTapalurRoRbHJAkInFAMlDYwvGHwxjgc1WtdL/8z8epjh4WXpPHtcA04FequkVEhgDPA//B+YMKSgY+DL5Q1ffDFahpnIjkAhOALyIcClDfPLQM2A18oKrRENcfgZ8AgQjH0RgF3heRPBG5IdLBuIYCRcDTblPfEyISbfO3LgNeinQQAKpagFMkdjuwEyiNks++VcB0Ecl0v9SfjTOdIiw8JQ9VXQP8GFjp3grlq+r9QGLIN03c51ZJ8DARkVSc/qjbVXV/pOMBcCsNjAcGAFPcfy8RIyLnArtVNS+ScTTjBFWdCJyF0/w4PdIB4XyLngg84taxqwDujmxIB7gTk8/HKYsUcSLSG7gApy+4P5AiIldGNipQ1bXA/wEfAO/iLK3hC9f1vc7zmIEzq3wrTj/GQOAa4NfAD4JNKCIyCXhIVSPeudZQVlaW5ubmRjoMY4zpVPLy8va0pzDiA8AZqroOQERG4twy3gS8KiLB9r1+wKVhiDfscnNzWbw4agazGGNMpyAijfYreU0e8cHEAaCq60UkXlUXichoYBTOHclXqlrX/nCNMSb6+PwB6vxKrS9Ard/5qQs+9wXwBxRfQAmo4vMr/oDiV8UfCODzu9sDznafP7jPPScQ3Bdo8PrAj++Q5wH8AerPaXhsMI77Lz6GwZnh7bbymjzyRORJ4Dn39RXutnjgZpyRGQDzROQxSyDGmHCq8fkprapjf1UdZdU+anwB6twP7Dp/wH3tfqj7/M5zd3/DD/jakPNqQ86rCTnu0Gs7rwMRGDsoAnExQmyMEBcTQ4xAXGwMsTFCrLjbYw88b/g6LiYGfwcE7jV53ATMxhnLLMAC4C84lXXj3efgFEp8BPheeMM0xnR2df4A+6vqKKmqo9T92V9VR0nlgdf1Pw22VdX5W36DJsTHCvGxMSTExZAQG0N8bAw94mLqt8XHCglxMaQnxJPgPo+PdY4NPj/4ePdacTEHHR8fG3PQh3zwg9x53fjz+oQQQ/05B+0XISYmOqfLtZg83Hkcee7kl9832Hdsg+KIH4nI8jDHaIyJEv6Ast/9QC855AO/9pAkUFJZV398RW3zCSA5IZb0pPj6n8GZyQe97pUcT8+keHomxjsf5iHJIJgYgh/qwYQQHxMTtR++nV2LyUNVA265iUGqur3Bbr+IDFPVTQAiMpQD5duNibjCkirmrSti7rrdbNxdTlxMg2+hcVL/rdH5IDr4m2Twg6jhN9f4Bsc613K3xR58flPvExd76Ej5QECpc9vHfX7F57Zl1/ndbQF3m9/Z5g8odf5GtgUUX4Nz6vzutsCBa9f5nXbz0Gv43HNrfIFDkkBZTfMjPRPjYw76wB/QO5n0/gcngODznqFJITGehDiv085MNGhNYcTVIvIlzpjvoB8Dc0VkM05z1mCcCYUtEpFZOCUQYoEn3HkjofvTcSYiDnLj/J27UiEishUow0lUvigr62AiqM4fYPHWfcxbv5t5XxWxblcZADm9khg/sBcBdT5ga/1KnS9ATV2Asmpffft2nfsBXBfaXu52fIZbjEC823bt8ztJw8PI+bARgfhgU4mbIOPcZpM4N/GlJ8XTt2cio/qm1X/YN0wCockgMT728P0CJqK8Jo/GCtzF4NQvGsHBo61qWrqYiMQCD+OsSpgPLBKROe5kxKDZwBpVPU9EsoF1IvKCqta6+2eqajQuNm8Os137q5m3bjfz1hXxyYY9lNX4iI8Vjs3N4OeTxjBjVDbD+6Qi0vbmC3/gQFIJJpjakM7VOp8eeB7aIesmqfrtbufsgdcB/H4lLng3EhNDXOyBD/D4WKftOz64PeQDPj7W2RYbc+CDP5iMDr6W8xi8RmzIcca0VbPJw62i21dV5zfYPh1nKv7/qOofgBWtfN8pwEZV3exe72WcGZqhyUOBNHH+x6fi1JgK2+xI03n5/AGW7ihh7ldOwliz05lc3y89kXPH9WPGqD6cMDyL1B5evxu1zOnAjLVv1sa4Wvrf9UfgZ41sr3T3LRSRh4C/E9KcFZxx3owcYEfI63zguAbHPATMwSkwlgZcqqrB2kTBekAKPKaq0br8owmTorIa5q93+i4+Xl/E/mofsTHC5MG9uWvWaGaOzmZU37R23V0YY7xrKXnkquohdxWqutgtyJfqbro3dDdwSgvXbex/eMPW3jOBZe61hgEfiMjHbg2nE1S1UET6uNu/civgHvwmTqG5GwAGDRrUQkgmmvgDyrIdJcxft5u564pYWVAKQJ+0Hsw6+ghmjurDCSOy6JkYH+FIjemeWkoezS1okqSqM9v4vvkcXN1xAIeWML4WuF+d4lsbRWQLMBpn7fRCAFXdLSJv4jSDHZI83DuSxwEmT54c8dLgpnl7y2tYsKGIeeuKmL++iJLKOmIEJg7qzZ1njmLGqGyO7NfT7i6MiQItJY9FInK9qv41dKOIXAe0p0rpImCEW9q9AKe88rcbHLMdp2b/xyLSF6dTfrNbGjpGVcvc52dw8J2P6SQCAWVlQSlz3buLFfklqEJWagKnju7LjFHZnDQii17JCZEO1RjTQEvJ43bgTRG5ggPJYjKQQDsWFVFVn4jcAryHM1T3KVVdLSI3ufsfBe4D/iYiK3Gaue5S1T3uXJI33W+fccCLqvpuW2Mxh1dJZS0LNuxh3le7mb++iL0VtYjA+IG9uOO0kcwc1Yej+ve0iV3GRDmvJdlnAsF1GVar6kcdGlUHmDx5slpV3cMvEFDW7NzvjIxaX8TS7fsIKGSkJDB9RBYzR/fhpBHZZKTY3YUx0UhE8hqbS+dpLKOqzgXmhlzsohaOf6PVEZouo7Sqjk827GGuO/diT7kz9WfcgHRuOWUEM0dlM3ZAL5tnYEwn1taB8Oe5j32A44HgnchMYB5gyaObqajx8d7qr3lzaQELN+3FH1DSk+KZPjKbmaOymT4ym6zUHpEO0xgTJm1KHqp6LYCIvA0cqao73df9cGaOm27A5w/w8cY9vLW0gPdX76Kqzs/AjCRunD6UU8f0YdyAXo3WbzLGdH7tnYKbG0wcrl3AyHZe00QxVWeE1BtLCnh7RSF7ymvplRzPxZNyuHBCDhMH9bahtMZ0A+1NHvNE5D2cJWkVZ8jt3OZPMZ3RjuJK3lpawJvLCthcVEFCXAynjenDN8bnMGNUH6uIakw3067koaq3iMiFHFhJ8HFVfbP9YZloUFJZyzsrd/LW0gIWbd0HwHFDMrjhpKGcdUw/0pNsdrcx3VU4KsctAcpU9UMRSRaRNFUtC8N1TQRU1/mZ+9Vu3lxawNx1u6nzKyP6pPKTWaO4YHwOOb2SIh2iMSYKtCt5iMj1OLWjMnDqT+UAj+LMDDedRCCgLNpazFvLCnhnxU72V/vITuvBNdNy+caEHI7qbyVBjDEHa++dx2yculJfAKjqBrdYoekENu4u440lBfxjWSEFJVUkJ8Qy66gjuHBiDscPy7J5GMaYJrU3edSoam3wW6mIxHFodVwTRXbvr2bO8kLeWlbAqoL9xMYIJ43I4iezRnH6kX1JTgjfGhjGmK6rvZ8U80XkZ0CSiJwOfB/4Z/vDMuFUUePj/TVf88aSAj7duIeAwtgB6fzPuUdy3rj+ZKfZ5D1jTOu0N3ncDVwHrARuBP7VsAKviQyfP8An7gS+99wJfAN6JzF75nAuGJ/D8D6pLV/EGGOa0N7k8QNV/RNQnzBE5DZ3mznMVJVVBft5c2kBc5YXsqe8hvSkeC6c6EzgmzSot1WrNcaERXuTxzVAw0TxnUa2mQ60o7iSfywr4M2lBWwqqiAhNoZTRvfhGxNymDk6mx5xtu62MSa82pQ8RORynMWbhojInJBdacDecARmmlde42POskLeWlrAl1uLAZgyJIPvnTSUs4/uR3qyTeAzxnSctt55LAR2AlnAAyHby4BD1jxvjIjMwrlDiQWeUNX7G+xPB54HBrlx/k5Vn/Zyble3qqCUm1/IY0dxFcOyU7jzzFGcP64/AzOSIx2aMaabaGtV3W3ANmBaW84XkVic6run46xnvkhE5qjqmpDDZgNrVPU8EckG1onIC4Dfw7ld1iuLd/Dfb60iIyWBl66fytShGTaBzxhz2LWrmp2ITBWRRSJSLiK1IuIXkf0eTp0CbFTVzapaC7wMXNDgGAXSxPlkTAWKAZ/Hc7uc6jo/P31jJT95bQWTBvfm7R+cyLRhmZY4jDER0d4O84dwKum+irO2+dXAcA/n5QA7Ql7nA8c1cu05QCFOX8qlqhoQES/nAiAiN+CUT2HQoEEewopO+fsq+f4LS1iRX8rNM4bxo9NH2joZxpiIavd0YlXdKCKxquoHnhaRhR5Oa+zrcsOZ6WcCy4BTcOpmfSAiH3s8Nxjb48Dj4Kxh7iGuqLNgfRG3vrwUv1957KpJnHnUEZEOyRhj2p08KkUkAVgmIr/B6URP8XBePjAw5PUAnDuMUNcC96uqAhtFZAsw2uO5nV4goDw0dyN/+HA9I/uk8ehVkxiS5eWP1hhjOl572z6uwhnxdAtQgfOhfrGH8xYBI0RkiJt8LsNpogq1Hbc6r4j0BUYBmz2e26mVVtbxvWcX8/sP1nPBuP68Oft4SxzGmKjS3sWgtrlPq4B7WnGeT0RuAd7DST5PqepqEbnJ3f8ocB/wNxFZidNUdZeq7gFo7Nz2/B7RZHVhKTc/v4SdpVXce8FRXDV1sHWKG2OijjitQq08yflAb/JEVR3bnqA6wuTJk3Xx4sWRDqNZr+Xl8/M3V9I7OYGHr5jIpMG9Ix2SMaabE5E8VZ3ccHtb7zzOdR9nu4/PuY9XAJVtvGa3VePzc88/1/DiF9uZNjSTB789gaxUq3RrjIle7ZkkiIicoKonhOy6W0Q+Be4NR3DdQUFJFd9/Po/l+aXcdPIwfnyGDcM1xkS/9o62ShGRE1X1EwAROR5vo60M8PGGIm59aSk+G4ZrjOlk2ps8rgOecutQAZQA323nNbu8QED5y7yNPPCBMwz3kSsnMjTb1tcwxnQe7R1tlQeME5GeOJ3vpeEJq+sqrarjR68s48O1u7lgfH9+fdExtvSrMabTaWtJ9itV9XkR+WGD7QCo6u/DEFuXs6ZwPzc9n0dhSRX3nH8UV0+zYbjGmM6prV95g/0aaeEKpKt7PS+fn725kl7J8fz9xmk2DNcY06m1dbTVY+6j54mB3VWNz8+9/1zDC19sZ+rQDB68fCLZaTYM1xjTubW12erPze1X1VvbFk7XUlhSxc0vLGH5jhJuPHkod54xyobhGmO6hLY2W+WFNYou6JMNe7j15aXU+gI8euVEZh3dL9IhGWNM2LS12eqZcAfSVQQCyiPzN/HA++sY3ieVR66cxDAbhmuM6WLaNUbUXR72LuBIIDG4XVVPaWdcnZIzDHc5H67dxfnjnGG4KT1sGK4xputp7yfbC8DfgXOAm4BrgKL2BtUZrd3pDMMt2FfFL847ku8cn2vDcI0xXVZ7e28zVfVJoE5V56vqd4GpYYirU3ljST4X/uVTquv8vHzDVK49YYglDmNMl9beO48693GniJyDs6LfAC8nisgs4E84a3I8oar3N9h/J06V3mCcY4BsVS0Wka1AGeAHfI2VCz4canx+7nt7Dc9/vp3jhmTw0LdtGK4xpntob/L4X7eu1Y+AB4GewB0tnSQiscDDwOk4y8ouEpE5qromeIyq/hb4rXv8ecAdqloccpmZwcWhIqGwpIrvv7CEZTtKuHH6UO4804bhGmO6j/Ymjy/celalwMxWnDcF2KiqmwFE5GXgAmBNE8dfDrzUnkDD6dONe/jBS84w3EeumMhZx9gwXGNM99Ler8oLReR9EblORFpTbyMH2BHyOt/ddggRSQZmAa+HbFbgfRHJE5EbWht0W6k61XCvevILMlMS+MctJ1jiMMZ0S+2tqjtCRKYAlwE/F5E1wMuq+nwLpzbWm9zUsrbnAZ82aLI6QVULRaQP8IGIfKWqCw55Eyex3AAwaNCgln6dZu2vdobhfrBmF+eN68/9NgzXGNONtbuRXlW/VNUf4jRFFQNeJhDmAwNDXg/A6WxvzGU0aLJS1UL3cTfwpvvejcX2uKpOVtXJ2dnZHsJq3Fdf7+f8Bz9h7le7+cV5R/Lny8Zb4jDGdGvtSh4i0lNErhGRfwMLgZ008UHewCJghIgMEZEEnAQxp5HrpwMnA/8I2ZYiImnB58AZwKr2/B7NeWtpAd94+FMqa20YrjHGBLX36/Ny4C3gXlX9zOtJquoTkVuA93CG6j6lqqtF5CZ3/6PuoRcC76tqRcjpfYE33Q/wOOBFVX23nb9Hkz7fvJdxA3rx4Lcn0CctseUTjDGmGxDVproaPJwsIupeQETOVdW3wxZZmE2ePFkXL17c6vNqfH5iRWwYrjGmWxKRvMbm0rXrE1EPzjz3tuda0apHXKwlDmOMaaBddx4HXUhkqapOCMvFOoCIFAHb2nh6FhCxCYnNsLhax+JqHYurdbpqXINV9ZARR21OHiJyrao+HfJ6iqp+2Y4Ao5aILI5UCZTmWFytY3G1jsXVOt0trva0x9wjIpcERz4BZ4rIGyIyMRyBGWOMiV7NjrYSkRVN7cIZ9fTfqvqqiJyIU6fqAeAR4LiwRmmMMSaqtDRUty9wJrCvwXbBmdfhd1+fAzyqqv8QkV+GNcLo8HikA2iCxdU6FlfrWFyt063iarbPQ0SeBJ5W1U8a2fciThXdAuA0YBJQBXypquM6IlhjjDHRoaXkMURVtzSzP1i0cKWqbhCRfsAxqvp++EM1xhgTLVrqMH8NQET+08T+fsA7buKYAVwCdJkRVyLylIjsFpEOK3/SFiIyUETmishaEVktIrdFOiYAEUkUkS9FZLkb1z2RjilIRGJFZKmIRNVEVhHZKiIrRWSZiLR+FmsHEZFeIvKaiHzl/jubFgUxjXL/nII/+0Xk9kjHBSAid7j/5leJyEsiEhXlKETkNjem1eH+s2rpzmMpTvmR7wF/aOSQq4HJQC5OqZE5wChVPTucQUaKiEwHyoFnVfXoSMcT5N7h9VPVJe5otzzgG6GLaUUoLgFSVLVcROKBT4DbVPXzSMYFICI/xPm32lNVz410PEHuqpiTI7mwWWNE5BngY1V9wq0/l6yqJREOq567oFwBcJyqtnX+VrhiycH5t36kqlaJyCvAv1T1bxGO62jgZZx6g7XAu8DNqrohHNdv6c7jMqAap2M9rZGfgKr6gIuAP6rqHTh3I12CW+a9uMUDDzNV3amqS9znZcBamlgP5XBSR7n7Mt79Cc8s1HYQkQE4gzqeiHQsnYGI9ASmA08CqGptNCUO16nApkgnjhBxQJKIxAHJNF0l/HAaA3yuqpXu5/R8nHqBYdHsaCtVXQf8n4isUNV/N9wvImeLyOU4dyDnuZvjwxWcaZmI5AITgC8iHApQ/40wDxgOPKyq0RDXH4Gf4HzhiTbBhc0UeExVo2HEzlCgCHhaRMbh/H3e1qBAaaQdslRDpKhqgYj8DtiOM2jo/Sjp910F/EpEMnHiOhsIW9Oop0mCjSUO17XANOBXqrpFRIYALS0EZcJERFJxVli8XVX3RzoeAFX1q+p4nDVapri3zhEjIucCu1U1L5JxNOMEVZ0InAXMdptKIy0OmAg84pYcqgDujmxIB7jNaOcDr0Y6FgBxVlG9ABgC9AdSROTKyEYFqroW+D/gA5wmq+WAL1zXb29hxDXAj4GV7odEvqreH5bITLPcPoXXgRdU9Y1Ix9OQ28wxD2c0XiSdAJzv9i28DJwiIlHzBcfrwmaHWT7O/+XgXeNrOMkkWpwFLFHVXZEOxHUasEVVi1S1DngDOD7CMQGgqk+q6kRVnY7TBB+W/g5of0n2GTgrB27FmTg4ELimsSVhIy0rK0tzc3MjHYYxxnQqeXl5exorjNhSeZKLWrjuz4Ez3L4RRGQkTjvkpLYG2lFyc3Npy3oexhjTnYlIo4MSWipPEuwE74NzG/aR+3omTpNEfDBxAKjqerc5xRjTDJ8/wIdrd/HMwm2syC9hSHYKI/umuT+pjOiTRk6vJGJibMljE51aGm11LYA7sepIVd3pvu4HPAzkuSVMnnNPuQJnZIYxphF7ymv4+6IdPP/5NnaWVpPTK4kLJuSwo7iSTzfu4Y0lBfXHJifEMqJPKiOCCaVvGqP6ptEvPRF3GWZjIsbrGua5wcTh2gWMxGmemg3citPnsQD4S1gjNKYLWLajhGcXbuXtFTup9Qc4cXgW95x/FKeO6UtsyN1FaWUdG3aXsX5XOet3lbFhdxnz1hXxWl5+/TFpPeIY3jeVkX3SGNE3tf6OpW/PHpZUzGHjqcNcRB4CRuD0ZyjOGOuNwMxomnndnLauYW5MW1XX+XlnxU6e/Wwry/NLSUmI5ZuTBnDVtMEM79O6KSf7KmpZv6uM9bvL2bCrzEksu8rZW1Fbf0zPxDhG9k2rv1NxnqeSnWpJxbRdU2uYex5tJSIX4sw6BVigqm+KyAvAT1V1e/hC7RiWPMzhUlhSxQtfbOPlL3ewt6KWodkpXDMtl4sm5pCWGN4uwb3lNfV3KcGEsn53GSWVdfXH9EqOP+QuZWTfVDJTe4Q1FtM1NZU8vDZbASwBylT1QxFJdmsq9QNWi8iXOBOJAFDV89sdsTGdiKry2ea9PLtwG++v+RqAU8f05ZppuZwwPLPDvvlnpvZgWmoPpg3LPCiWovIaJ5HscprANuwqY87yQsqqD8wRy0xJqE8oI/qmMbKP87x3SkKHxGq6Fk/JQ0SuB24AMoBhOHWUHgWipmqqMZFQUePjzaUFPPvZVtbvKqdXcjw3TB/GFccNYmBGckRiEhH6pCXSJy2RE4Zn1W9XVXbtrznkLuWNJQWU1xxIKlmpPRh1RCqDMlJIiBViY2KIjeHgR5FGtkFsrLMvLkaIiWnw6G6PbepHmt8WvFZyQizJCa353ms6gte/gdk4M1+DM04VpxN9fuhBbmmFAozp4jYXlfPc59t4bXE+ZTU+js7pyW+/OZbzxvUnMT420uE1SkQ4Ij2RI9ITmT7ywJwvVWVnaTXrdpW5/SnOncr7q7/GF1ACAcUXUPyq+APOTySJwJH9enLckEymDs1gypAMeiXb3dLh5jV51Khqbcit9584sARtqEqcInTnNbLPmE7NH1DmrdvNM59tY8H6IuJjhbOP6cfV03KZOKhXp+2UFhH690qif68kZo7q0+LxqkpAqU8kflX8fufRFwgQCHDwo7rJJ+QnoIrPf3BCOugnZHtoAguosre8lkVbi3nhi2089ekWRGDMET2ZOjST44ZmcJwlk8PCa/KYLyI/wyk5fDpwEvBgw4NUdbFb5dWYLqOkspZXF+fz3Ofb2F5cSd+ePfjh6SO5bMpA+qRFxZo/h5WIOE1UEZ7AWOPzs3xHKZ9v3svnm/celExGH9GTqUMznIRiyaRDeB2qGwNcB5yBM59juqo2+hVFRDaq6vCQ17Nw7lRigScaFk4UkTtxJheCk8zGANlACvAscAQQAB5X1T+55/wSuB6nbDTAz1T1X839Djba6vDI27aPd1bsZGBGEkOzUxmalUL/XkkR/6BpizWF+3n2s628tayA6roAU4ZkcM20XM44qi/xse2qKWo6QI3Pz4r8Uj7ftJfPt+wlb9s+qusCAIw+Io2pQzPrk4kNCvCuXUN1ReS24Ae3+/ol99zLGhx3HU6tq0vd17HAeuB0nEqdi4DLm1rxTkTOA+5Q1VOaWy3PTR7lqvo7L788WPI4HDYXlXPBQ59SUesjtFk8ITaGwZnJDM1OYUiWk1Cc5ylkpCREVXNPnT/Au6u+5tnPtrJo6z4S42O4cMIArp42mDH9ekY6PNMKocnkiy3FLN5W3EgyyWDKkEwyLJk0qb1Dda/BuXsIuh3YJCLzOFCOZDKQwMErVU0BNqrqZjeIl3Hq3je1XOrluAu8uDPad7rPy0QkuFpeRJdaNY0rr/Fxw3N5xMfFsOD2mSTExbClqIIte5yfTUUVbNxdzkdf7abOfyCz9EyMY0h2KsOynGQyJDuFoVmp5GYlH9YRNbv3V/Pil9t58Yvt7C6rYVBGMv91zhgumTSQ9GQr19YZ9YiL5djcDI7NzeAHQK0vwIr8EreZq5iXF23nbwu3AgeSyXFDnA54mwPTspbWML8c+DZwIvBxyK40nA7zXwHBGearVfWjBud/E5ilqt9zX1+Fs+bwLY28VzLO3clwVS1usC8Xp/TJ0aq6373z+A6wH2dlrB+p6r7mflG78+g4gYBy8wt5fLh2N89dN4Xjh2U1eazPH6CgpIrNRRVs3lPBlj3lbNlTweaiCnaWVh90bL/0xPo7lNA7lpxeScSFodlIVVmyfR9/W7iNf6/ciS+gzBiVzTXTcjl5ZLYVJezian0BVhaU8PnmYj7fvJfFW/dRVeeMAxrVN62+zyRak0llrY89ZbXsqahhb3kte8pr2Ftew57657XsrXBev3Lj1FZXNQhq653HQpxv/1nAAyHby4AV7rq4c5t730a2NZWtzgM+bSRxNLZa3iPAfe617nNj++4hby5yA878FAYNGtRMmKY9Hpm/ifdW7+K/zhnTbOIAiIuNYXBmCoMzU5jZYF9lrY+teyrdZOImlT0VzFlWyP6QyW3xscKgjOT6PpUhWSkMzU5lSFYKWaktN4NV1/mZs6yQZz7byurC/aQlxnHN8blcNXUwuVkpbf1jMJ1MQlwMkwZnMGlwBrNnDj8kmbyyOJ9nPnOqkY/sm1rfZzJlSAZZHZBM/AFlX2Wt86FfXkNRaAIoO5AIgokhmOgaSkuMIyu1B1mpCQzNSmXKkIQOGT7ersWgWry4yDTgl6p6pvv6pwCq+utGjn0TeFVVXwzZFg+8Dbynqr9v4j1ygbdbqrFldx4dY+663Xz3b4s4f1x//njp+A7pv1BViitq65NJaHLZureSWl+g/ti0HnFu05dzt3LgeQrFFbU8//k2/r54ByWVdYzqm8Y1x+fyjQn9bdKZOUSdP+D0mbijuULvTEb2TXXnmTjDg5tKJtV1forKathbUcuesppDEkBoYiiuqKWxKTSxMUJmSgKZbkLISu1BZkoCWWkHHrNSepCZmkBmagI94sKbKNrbYT4VZ2juGJx+jVigQlWb7UEUkTicDvNTcSYPLgK+raqrGxyXDmwBBqpqhbtNcFYpLFbV2xsc3y+kPPwdOE1hB3XeN2TJI/y27qng/Ic+Iad3Mm/cfDxJCYd/cpw/oBSWVDlJJeRuZXNRBYWlVTT85x0bI5x5VF+unpbLcUMyoqqz3kS3On+AlQWl9X0mi7cWU1nrJJMRfVI5Oied8hpffdPR3vIaKmobvztISYg98OGf2uPgxJCaQGZKD7LTnMf0pPiINqG2N3ksxqmk+ypOx/jVOH0TP/dw7tk4EwdjgadU9VcichOAqj7qHvMdnL6Ry0LOC/azrMQZqgvukFwReQ4Yj9NstRW4sUHJ+ENY8givihofF/1lIbvKqvnnLSdGrBRHc6rr/GzbW8mWPeVsKnJKr100MYd+6UkRjsx0BcFk8oXbzLXu6zJ6JcfXf/gHE0F2MCG4CSIzpUdEvmi1VbuTh6pOFpEVqjrW3bZQVaNikXcvLHmEj6pyy4tL+feqnTzz3SmcNOKQ5Y2NMV1Ee4fqVopIArBMRH6D04luPYvd1GMLNvPOyp389KzRljiM6aa8jne8CqfZ6Rac0usDgYs7KigTvRasL+I3737FOWP7ccP0oZEOxxgTIZ7uPFR1m/u0CivD3m1t31vJD15aysi+afz2m2Ots9mYbqzZ5CEiK2l6XgbB/g/T9VXW+rjhucWoKo9dNcmGthrTzbX0CXCu+zjbfXzOfbwCp/y66QZUlbtfX8m6XWU8/Z1jGZxp3V3GdHfNJo9gc5WInKCqJ4TsultEPgXu7cjgTHR48pMtzFleyJ1njmKGh/UejDFdn9cO8xR33gUAInI8NtqqW1i4cQ+//vdXzDrqCL4/Y1ikwzHGRAmvDdfXAU+5M8EBSmiklpTpWvL3VXLLS0sZkpXC7741zjrIjTH1PN15qGqeqo4DxgLjVHW8qi7xcq6IzBKRdSKyUUTubmT/nSKyzP1ZJSJ+Eclo7lwRyRCRD0Rkg/vY29uva7yqrvNz0/N51PkCPH7VJFJ7WAe5MeaAlkZbXamqz4vIDxtsB6CpYoUhx8UCDxOyGJSIzAldDEpVfwv81j0+uBhUcQvn3g38R1Xvd5PK3cBdrfi9TTNUlZ+9uZJVBft58prJDM1OjXRIxpgo09KdR7BfI62Jn5bULwalqrVAcDGoptQvBtXCuRfgFE3EffyGh1iMR88s3MobSwq447SRnDqmb6TDMcZEoZZGWz3mPrZ1YmAOsCPkdT5wXGMHuotBzcKZxd7SuX2DhRBVdaeI2BCgMPl8817ue2ctp43pyw9OGd7yCcaYbqmlZqs/N7dfVW9t4frtWQyqNec2/ua2GFSrFJZUMfuFJQzOTOb3l46zlfSMMU1qqRc0r4X9LcnHqYMVNAAobOLYyzjQZNXSubuCa3qISD9gd2MXVNXHgcfBqarb+vC7j+o6Pzc/n0eNL8DjV02mZ6Kt222MaVpLzVbPNLffg0XACBEZgrMY1GU4a6IfxB0CfDJwpcdz5wDXAPe7j/9oZ5zdmqry32+tYnl+KY9dNYnhfayD3BjTPE/jL0UkG2c005FAYnC7qp7S3Hmq6hORW4D3OLAY1OqGi0EBFwLvB1cRbO5cd/f9wCsich2wHbjEy+9hGvf8F9t5NS+fW08ZzplHHRHpcIwxnYDXxaDeB/4O/Bi4CefbfpGqdprhsbYYVOMWbS3m8sc/56QRWTx5zbHWz2GMOUhTi0F5LU+SqapPAnWqOl9VvwtMDWuE5rD7urSam59fwoDeSfzxsgmWOIwxnnmdNlznPu4UkXNwOq4HdExI5nCo8fm5+YU8Kmt9vHj9caQnWQe5McY7r8njf91O7R8BDwI9gTs6LCrT4X45Zw1Lt5fwyBUTGdnXy3xPY4w5wGvy+EJVS4FSYGYHxmMOgxe/2M5LX27n+zOGcdYx/SIdjjGmE/La57FQRN4XkeusCGHntmT7Pn4xZxXTR2bzozNGRTocY0wn5bWq7gjgv4CjgDwReVtErmzhNBNldpdVc/PzeRyRnsifLxtPrHWQG2PayOudB6r6par+EKdgYTEHChOaTqDWF2D2C0vYX+Xj8asm0ys5IdIhGWM6MU/JQ0R6isg1IvJvYCGwEyeJdHmFJVVU1PgiHUa7/e87a1i0dR//982xjOnXM9LhGGM6Oa93HsuB8cC9qjpSVe9SVU91r1paDMo9Zoa7GNRqEZnvbhsVskjUMhHZLyK3u/t+KSIFIfvO9vh7tNp9b6/h2F99yI9fXc7nm/cSCHS+ElmvLN7Bs59t44bpQzl/XP9Ih2OM6QK8jrYaqu5UdBE5V1Xf9nKSl8WgRKQX8BdglqpuD5ZXV9V1OAkreJ0C4M2Qy/9BVX/nMf42+95JQ+iZGM87K3fyWl4+AzOSuHjiAC6eOICBGckd/fbttnxHCf/11ipOGJ7JT860DnJjTHh4Sh56cA2TewFPyYOQBZ0ARCS4oNOakGO+Dbyhqtvd92qsQu6pwCZV3ebxfcNm0uAMJg3O4BfnH8l7q7/m9bwC/vSfDfzxww1MHZrBxRMHcPYx/UiJwmVa95TXcNPzeWSn9uDByycSF+u5i8sYY5rVlk+T1gzRaWxBp5wGx4wEeovIPBHJE5GrG7lOw3LtALeIyAoReepwDB9OTojjwgkDeP57x/HJXafw4zNG8nVpNXe+toJjf/UhP3plOZ9tip5mrTq/00FeXFHLY1dNIiPFOsiNMeHTlq/LN7biWC8LOsUBk3DuLpKAz0Tkc1VdDyAiCcD5wE9DznkEuM+91n3AA8B3D3nzDloMKqdXErecMoLZM4eTt20fr+Xl8/aKnby+JJ8BvQ80aw3KjFyz1v/711q+2FLMHy4dx9E56RGLwxjTNXkdbXWJiARrWJwpIm+IyEQPp3pZDCofeFdVK1R1D7AAGBey/yxgiaruCm5Q1V2q6lfVAPBXmhj5paqPq+pkVZ2cnZ3tIdzWEREm52Zw/8VjWfTz0/jTZeMZkpXCnz/awPTfzuVbj33GK4t3UH6YR2u9sSSfpz/dyndPGMKFE6wEmTEm/Lw2W/23qpaJyIk4nd/P4Hz7b0n9gk7uHcRlOAs5hfoHcJKIxLnrmB8HrA3ZfzkNmqzc1QODLgRWefw9OkxSQiwXjM/hueuO49O7TuHOM0dRVFbDT15bwbH/+yE/fGUZCzft6fBmrVUFpfz0jZVMHZrBT88e3aHvZYzpvrw2W/ndx3OAR1X1HyLyy5ZO8rIYlKquFZF3gRVAAHhCVVcBuMnkdA5tKvuNiIzHabba2sj+iOrfK4nZM4fz/RnDWLJ9H6/lFfD28kLeWFJATq8kLp40gIsn5jA4MyWs71tcUcuNz+WRmZLAQ9+eSLx1kBtjOojXxaDexhkqexpO/0QV8KWqjmv2xCgS6cWgquv8vLf6a17Ly+eTjXtQhSm5GXxz0gDOHtuP1HaO1vL5A1z91Jcs3raP126axtgBvcITuDGmW2tqMSivySMZmAWsVNUNbrPRMar6fvhD7RiRTh6hdpZW8ebSAl7Ly2dzUQVJ8bGcdfQRfHPSAKYOzWzToky/emcNf/14C7/95lgumTyw5ROMMcaD9iaPYUC+qtaIyAxgLPCsqpaEOc4OE03JI0hVWbqjhNfy8vnn8kLKqn3k9Eriook5XDxxALlZ3pq1/rGsgNteXsbV0wZz7wVHd3DUxpjupL3JYxkwGcjF6b+YA4xS1Q4rCxJu0Zg8QlXX+Xl/zS5ez8vn4w1FBBSOze3tNGsd04+0xMZX+ltTuJ+LHvmUY3LSeeF7U0mIs34OY0z4tDd5LFHViSLyE6BKVR8UkaWqOqEjgu0I0Z48Qn1dWu02a+1gU1EFifExnHV0Py6eOIDjhx1o1tpXUcv5D39CrS/AP39wIn3SEiMcuTGmq2kqeXhew1xELgeuBs5zt9mi1x3kiPREbp4xjJtOHsqyHSW8viSfOcsKeXNpAf3TE7lo4gC+MSGHe/65ml2lNbx841RLHMaYw8rrnceRwE3AZ6r6kogMAS5V1fs7OsBw6Ux3Ho2prvPz4dpdvJaXz4L1TrMWwP0XHcNlU8I3e94YY0K1q9nKvUACTh0qgHWqWhfG+DpcZ08eoXbtr+atpQXExcZw3YlDIh2OMaYLa1ezlTvC6hmcCXkCDBSRa1R1QRhjNB717ZnIjScPi3QYxphuzGufxwPAGe4aG4jISJySIZM6KjBjjDHRy2ufxwpVHdvStmgmIkVAW9cDyQL2hDGccLG4Wsfiah2Lq3W6alyDVfWQyrJek8fTOHWnnnM3XQHEqeq17Qio0xCRxY21+UWaxdU6FlfrWFyt093i8tpsdRMwG7gVp89jAc7SscYYY7qhFpOHiMQAeap6NPD7jg/JGGNMtGuxloW74NJyEenOkwkej3QATbC4Wsfiah2Lq3W6VVxe+zw+Ao4FvgQqgttV9fyOCMoYY0x089rncU+HRmGMMaZTabbZSkSGi8gJqjo/9AdnBb/8wxNi5IjIUyKyW0QivsxtKBEZKCJzRWStiKwWkdsiHROAiCSKyJcistyNK2q+dIhIrIgsdRc2ixoislVEVorIMhGJmhIIItJLRF4Tka/cf2fToiCmUe6fU/Bnv4jcHum4AETkDvff/CoReUlEoqLYnIjc5sa0Otx/Vi31efwRKGtke6W7r6v7G84iWNHGB/xIVccAU4HZbv2xSKsBTnFXmBwPzBKRqZENqd5twNpIB9GEmao6PsqGef4JeFdVRwPjiII/O1Vd5/45jceZoFwJvBnZqEBEcnBGok52BxbFApdFNioQkaOB64EpOH+H54rIiHBdv6XkkauqKxpuVNXFOGt7dGlu+ZXiSMfRkKruVNUl7vMynP/YOZGNCtRR7r6Md3+8FU/rQCIyADgHeCLSsXQGItITmA48CaCqtVG48NupwCZVbevE33CLA5JEJA5IBgojHA/AGOBzVa1UVR8wH7gwXBdvKXk0d+uVFK4gTNuJSC4wAfgiwqEA9c1Dy4DdwAeqGg1x/RH4Cc5E12ijwPsikiciN0Q6GNdQoAh42m3qe0JEvC1refhchlMiKeJUtQD4HbAd2AmURskS3auA6SKS6S4lfjYQtjWqW0oei0Tk+oYbReQ6IC9cQZi2EZFU4HXgdlXdH+l4AFTV7zYrDACmuLfOESMi5wK7VTVa/72eoKoTgbNwmh+nRzognG/RE4FH3AXfKoC7IxvSAW6F7/OBVyMdC4CI9AYuAIYA/YEUEbkyslGBqq4F/g/4AHgXWI7T5B0WLSWP24FrRWSeiDzg/swHvofThmwiRETicRLHC6r6RqTjacht5phH5PuMTgDOF5GtwMvAKSLyfGRDOkBVC93H3Tjt91MiGxHgDIbJD7lrfA0nmUSLs4Alqror0oG4TgO2qGqRu1TFG8DxEY4JAFV9UlUnqup0nCb4DeG6drPJQ1V3qerxOEN1t7o/96jqNFX9OlxBmNYREcFpj16rqlEz619EskWkl/s8Cec/1VeRjElVf6qqA1Q1F6ep4yNVjfi3QgARSRGRtOBz4AycpoaIcv9v7xCRUe6mU4E1EQypocuJkiYr13Zgqogku/83TyUKBhgAiEgf93EQcBFh/HPzNM9DVecCc8P1pp2FiLwEzACyRCQf+IWqPhnZqADn2/RVwEq3fwHgZ6r6r8iFBEA/4BkRicX5YvKKqkbV0Ngo0xd40/m8IQ54UVXfjWxI9X4AvOA2EW0GoqIIqtt2fzpwY6RjCVLVL0TkNWAJTrPQUqJntvnrIpIJ1AGzVXVfuC7seSVBY4wxJqjF2lbGGGNMQ5Y8jDHGtJolD2OMMa1mycMYY0yrWfIwxhjTapY8TJfiTmg9s8G220WkyWWT3XM6tCihW2l1hYjc0WD7L0Xkx+7zRBH5QER+0cj5l7jVbds8ZF5EykOeny0iG0RkkBtDZXBOQCPHqog8EPL6xyLyy7bGYboGSx6mq3mJQyuaRrQOkogcARyvqmNV9Q9NHJOAUzEgT1UbK2V/HfB9VZ3p8T2bnMMlIqcCDwKzVHW7u3kP8KMmTqkBLhKRLC/vbboHSx6mq3kNp/R0D6gvHNkf+EREHhGRxc2tNdLgG/c3ReRv7vNsEXldRBa5Pyc0cm6iiDwtzvocS0Uk+EH/PtDHXYPipEbeNg6ndMoGVT2khpSI/A9wIvCoiPy2qfcRke+IyKsi8k/3PRv7/U4C/gqco6qbQnY9BVwqIhmNnObDmfR2RyP7TDdlycN0Kaq6F2e55GBNrcuAv6szG/bn7poZY4GTRWRsKy79J+APqnoscDGNl3ef7cZwDE4JjWfEWRTofJzy4eNV9eNGzvsJ4FPV25v4ne4FFgNXqOqdzbwPwDTgGlU9pZFL9QD+AXxDVRuWjSnHSSBN1ax7GLhCRNKb2G+6GUsepisKbboKbbL6logswSkfcRTQmgW0TgMecsvBzAF6ButShTgReA7A/XDeBoz0cO1PgGki4uXYlt7nA1Vtag2aOmAhThNYY/4MXCPOeh4Hcas2P4uz6JExljxMl/QWcKqITASSVHWJiAwBfgycqqpjgXdofL2a0Ho9oftjgGnBlexUNcddiCuUtDHeBTgVrP8tIv09HN/c+1Q0sy8AfAs4VkR+1nCnWwn5ReD7TZz/R5zEE21re5gIsORhuhx3NcN5OM0wwbuOnjgfrKUi0henrHdjdonIGBGJ4eBV194Hbgm+EJHxjZy7ALjC3T8SGASs8xjz68BvgXeDlYmb0Z73qQTOxWmCauwO5Pc4RQcP6XB372heoek7F9ONWPIwXdVLOOs2vwygqstxmqtW4ySVT5s4727gbeAjnFXhgm4FJrvDbdcANzVy7l+AWBFZCfwd+I6q1ngNWFUfxVkLYk5IH0Zj2vs+xTh9Qv8lIhc02LcHZ12RHk2c/gBgo66MVdU1xhjTenbnYYwxptUseRhjjGk1Sx7GGGNazZKHMcaYVrPkYYwxptUseRhjjGk1Sx7GGGNazZKHMcaYVvv/e8Yg0T1mixIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k_range = range(1,10)\n",
    "k_scores= []\n",
    "\n",
    "for k in k_range:\n",
    "    knn=KNeighborsClassifier(k)\n",
    "    scores=cross_val_score(knn,X_train_scaled,y_train,cv=10,scoring=\"accuracy\")\n",
    "    k_scores.append(scores.mean())\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-validated accuracy')\n",
    "k_scores= []\n",
    "\n",
    "for k in k_range:\n",
    "    knn=KNeighborsClassifier(k)\n",
    "    scores=cross_val_score(knn,X_train_scaled,y_train,cv=10,scoring=\"roc_auc\")\n",
    "    k_scores.append(scores.mean())\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-validated roc_auc')\n",
    "\n",
    "k_scores= []\n",
    "\n",
    "for k in k_range:\n",
    "    knn=KNeighborsClassifier(k)\n",
    "    scores=cross_val_score(knn,X_train_scaled,y_train,cv=10,scoring=\"f1\")\n",
    "    k_scores.append(scores.mean())\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-validated f1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53783378",
   "metadata": {},
   "source": [
    "- 이웃하는 개수, 매개변수 k를 늘려감에 따라, AUC_ROC_SCORE와 f1_score 추이를 비교해봤을 때, 3~6사이가 적당해 보인다.\n",
    "- k=5로 정하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f561853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.7798507462686567\n",
      "정밀도 : 0.75\n",
      "재현율 : 0.6407766990291263\n",
      "F1 스코어 : 0.6910994764397905\n",
      "ROC_AUC_SCORE : 0.7537216828478965\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred[0]</th>\n",
       "      <th>Pred[1]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True[0]</th>\n",
       "      <td>143</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True[1]</th>\n",
       "      <td>37</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pred[0]  Pred[1]\n",
       "True[0]      143       22\n",
       "True[1]       37       66"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf =KNeighborsClassifier(5) #### k = 5 \n",
    "knn_clf.fit(X_train_scaled,y_train)\n",
    "y_pred_knn_clf = knn_clf.predict(X_test_scaled)\n",
    "\n",
    "print(f\"정확도 : {accuracy_score(y_test, y_pred_knn_clf)}\")\n",
    "print(f\"정밀도 : {precision_score(y_test, y_pred_knn_clf)}\")\n",
    "print(f\"재현율 : {recall_score(y_test, y_pred_knn_clf)}\")\n",
    "print(f\"F1 스코어 : {f1_score(y_test, y_pred_knn_clf)}\")\n",
    "print(f\"ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_knn_clf)}\")\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred_knn_clf),\n",
    "             index=['True[0]', 'True[1]'],\n",
    "             columns=['Pred[0]','Pred[1]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ad7b8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브베이즈 정확도 : 0.6902985074626866\n",
      "나이브베이즈 정밀도 : 0.6428571428571429\n",
      "나이브베이즈 재현율 : 0.4368932038834951\n",
      "나이브베이즈 F1 스코어 : 0.5202312138728323\n",
      "나이브베이즈 ROC_AUC_SCORE : 0.6426890261841718\n",
      "SVC 정확도 : 0.8097014925373134\n",
      "SVC 정밀도 : 0.776595744680851\n",
      "SVC 재현율 : 0.7087378640776699\n",
      "SVC F1 스코어 : 0.7411167512690355\n",
      "SVC ROC_AUC_SCORE : 0.7907325684024714\n",
      "인공신경망분류 정확도 : 0.7985074626865671\n",
      "인공신경망분류 정밀도 : 0.7634408602150538\n",
      "인공신경망분류 재현율 : 0.6893203883495146\n",
      "인공신경망분류 F1 스코어 : 0.7244897959183674\n",
      "인공신경망분류 ROC_AUC_SCORE : 0.7779935275080907\n",
      "KNN 정확도 : 0.7798507462686567\n",
      "KNN 정밀도 : 0.75\n",
      "KNN 재현율 : 0.6407766990291263\n",
      "KNN F1 스코어 : 0.6910994764397905\n",
      "KNN ROC_AUC_SCORE : 0.7537216828478965\n"
     ]
    }
   ],
   "source": [
    "print(f\"나이브베이즈 정확도 : {accuracy_score(y_test, y_pred_clf)}\")\n",
    "print(f\"나이브베이즈 정밀도 : {precision_score(y_test, y_pred_clf)}\")\n",
    "print(f\"나이브베이즈 재현율 : {recall_score(y_test, y_pred_clf)}\")\n",
    "print(f\"나이브베이즈 F1 스코어 : {f1_score(y_test, y_pred_clf)}\")\n",
    "print(f\"나이브베이즈 ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_clf)}\")\n",
    "\n",
    "print(f\"SVC 정확도 : {accuracy_score(y_test, y_pred_svc)}\")\n",
    "print(f\"SVC 정밀도 : {precision_score(y_test, y_pred_svc)}\")\n",
    "print(f\"SVC 재현율 : {recall_score(y_test, y_pred_svc)}\")\n",
    "print(f\"SVC F1 스코어 : {f1_score(y_test, y_pred_svc)}\")\n",
    "print(f\"SVC ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_svc)}\")\n",
    "\n",
    "print(f\"인공신경망분류 정확도 : {accuracy_score(y_test, y_pred_mlpc)}\")\n",
    "print(f\"인공신경망분류 정밀도 : {precision_score(y_test, y_pred_mlpc)}\")\n",
    "print(f\"인공신경망분류 재현율 : {recall_score(y_test, y_pred_mlpc)}\")\n",
    "print(f\"인공신경망분류 F1 스코어 : {f1_score(y_test, y_pred_mlpc)}\")\n",
    "print(f\"인공신경망분류 ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_mlpc)}\")\n",
    "\n",
    "print(f\"KNN 정확도 : {accuracy_score(y_test, y_pred_knn_clf)}\")\n",
    "print(f\"KNN 정밀도 : {precision_score(y_test, y_pred_knn_clf)}\")\n",
    "print(f\"KNN 재현율 : {recall_score(y_test, y_pred_knn_clf)}\")\n",
    "print(f\"KNN F1 스코어 : {f1_score(y_test, y_pred_knn_clf)}\")\n",
    "print(f\"KNN ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_knn_clf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b0cb961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브베이즈 F1 스코어 : 0.5202312138728323\n",
      "나이브베이즈 ROC_AUC_SCORE : 0.6426890261841718\n",
      "SVC F1 스코어 : 0.7411167512690355\n",
      "SVC ROC_AUC_SCORE : 0.7907325684024714\n",
      "인공신경망분류 F1 스코어 : 0.7244897959183674\n",
      "인공신경망분류 ROC_AUC_SCORE : 0.7779935275080907\n",
      "KNN F1 스코어 : 0.6910994764397905\n",
      "KNN ROC_AUC_SCORE : 0.7537216828478965\n"
     ]
    }
   ],
   "source": [
    "#print(f\"나이브베이즈 정확도 : {accuracy_score(y_test, y_pred_clf)}\")\n",
    "#print(f\"나이브베이즈 정밀도 : {precision_score(y_test, y_pred_clf)}\")\n",
    "#print(f\"나이브베이즈 재현율 : {recall_score(y_test, y_pred_clf)}\")\n",
    "print(f\"나이브베이즈 F1 스코어 : {f1_score(y_test, y_pred_clf)}\")\n",
    "print(f\"나이브베이즈 ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_clf)}\")\n",
    "\n",
    "#print(f\"SVC 정확도 : {accuracy_score(y_test, y_pred_svc)}\")\n",
    "#print(f\"SVC 정밀도 : {precision_score(y_test, y_pred_svc)}\")\n",
    "#print(f\"SVC 재현율 : {recall_score(y_test, y_pred_svc)}\")\n",
    "print(f\"SVC F1 스코어 : {f1_score(y_test, y_pred_svc)}\")\n",
    "print(f\"SVC ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_svc)}\")\n",
    "\n",
    "#print(f\"인공신경망분류 정확도 : {accuracy_score(y_test, y_pred_mlpc)}\")\n",
    "#print(f\"인공신경망분류 정밀도 : {precision_score(y_test, y_pred_mlpc)}\")\n",
    "#print(f\"인공신경망분류 재현율 : {recall_score(y_test, y_pred_mlpc)}\")\n",
    "print(f\"인공신경망분류 F1 스코어 : {f1_score(y_test, y_pred_mlpc)}\")\n",
    "print(f\"인공신경망분류 ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_mlpc)}\")\n",
    "\n",
    "#print(f\"KNN 정확도 : {accuracy_score(y_test, y_pred_knn_clf)}\")\n",
    "#print(f\"KNN 정밀도 : {precision_score(y_test, y_pred_knn_clf)}\")\n",
    "#print(f\"KNN 재현율 : {recall_score(y_test, y_pred_knn_clf)}\")\n",
    "print(f\"KNN F1 스코어 : {f1_score(y_test, y_pred_knn_clf)}\")\n",
    "print(f\"KNN ROC_AUC_SCORE : {roc_auc_score(y_test, y_pred_knn_clf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b852cee",
   "metadata": {},
   "source": [
    "- 나이브베이즈와, 최적의 매개변수를 탐색한 SVC, 인공신경망분류, KNN 모델을 비교했을때, __SVC 모델__(그다음 인공신경망분류 모델) 이 유사하게 Test 데이터 셋에 대해 잘 적합하였다고 할 수 있다.\n",
    "    - 근거1. Test 데이터에 대해 TPR가 가장 높고, FPR가 가장 낮은 비율을 차지하는 모델 (ROC_AUC_SCORE가 가장 1에 가까운)\n",
    "    - 근거2. Test 데이터에 대해 recall_score 와, precision_score 둘다 높은 모델 (F1 SCORE)\n",
    "- 단, SVC, 인공신경망분류 모델에서 보다 최적의 매개변수를 도출하기 위해서는 상당한 시간이 소요된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83bc10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "422px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
